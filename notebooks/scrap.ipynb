{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CosineAnnealingLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        warmup_epochs: int,\n",
    "        max_epochs: int,\n",
    "        warmup_start_lr: float = 0.00001,\n",
    "        eta_min: float = 0.00001,\n",
    "        last_epoch: int = -1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            optimizer (torch.optim.Optimizer):\n",
    "                最適化手法インスタンス\n",
    "            warmup_epochs (int):\n",
    "                linear warmupを行うepoch数\n",
    "            max_epochs (int):\n",
    "                cosine曲線の終了に用いる 学習のepoch数\n",
    "            warmup_start_lr (float):\n",
    "                linear warmup 0 epoch目の学習率\n",
    "            eta_min (float):\n",
    "                cosine曲線の下限\n",
    "            last_epoch (int):\n",
    "                cosine曲線の位相オフセット\n",
    "        学習率をmax_epochsに至るまでコサイン曲線に沿ってスケジュールする\n",
    "        epoch 0からwarmup_epochsまでの学習曲線は線形warmupがかかる\n",
    "        https://pytorch-lightning-bolts.readthedocs.io/en/stable/schedulers/warmup_cosine_annealing.html\n",
    "        \"\"\"\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.max_epochs = max_epochs\n",
    "        self.warmup_start_lr = warmup_start_lr\n",
    "        self.eta_min = eta_min\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "        return None\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch == 0:\n",
    "            return [self.warmup_start_lr] * len(self.base_lrs)\n",
    "        if self.last_epoch < self.warmup_epochs:\n",
    "            return [\n",
    "                group[\"lr\"] + (base_lr - self.warmup_start_lr) / (self.warmup_epochs - 1)\n",
    "                for base_lr, group in zip(self.base_lrs, self.optimizer.param_groups)\n",
    "            ]\n",
    "        if self.last_epoch == self.warmup_epochs:\n",
    "            return self.base_lrs\n",
    "        if (self.last_epoch - 1 - self.max_epochs) % (2 * (self.max_epochs - self.warmup_epochs)) == 0:\n",
    "            return [\n",
    "                group[\"lr\"] + (base_lr - self.eta_min) * (1 - math.cos(math.pi / (self.max_epochs - self.warmup_epochs))) / 2\n",
    "                for base_lr, group in zip(self.base_lrs, self.optimizer.param_groups)\n",
    "            ]\n",
    "\n",
    "        return [\n",
    "            (1 + math.cos(math.pi * (self.last_epoch - self.warmup_epochs) / (self.max_epochs - self.warmup_epochs)))\n",
    "            / (1 + math.cos(math.pi * (self.last_epoch - self.warmup_epochs - 1) / (self.max_epochs - self.warmup_epochs)))\n",
    "            * (group[\"lr\"] - self.eta_min)\n",
    "            + self.eta_min\n",
    "            for group in self.optimizer.param_groups\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1)\n",
    "max_epoch = 128  # 学習終了のepoch数は最初から与える\n",
    "iter_step = 4  # (ダミー)ミニバッチで学習する場合のイテレーションステップ数=バッチサイズ/ミニバッチサイズ\n",
    "\n",
    "optimizer = torch.optim.AdamW(  \n",
    "    model.parameters(), \n",
    "    lr=0.001,\n",
    "    weight_decay=0.02)\n",
    "\n",
    "lr_scheduler = CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    max_epochs=max_epoch,\n",
    "    warmup_epochs=8,\n",
    "    warmup_start_lr=0.0001,\n",
    "    eta_min=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m         curves \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# 各epoch終了後にスケジューラで最適化学習率を更新\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(curves)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_curves.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:154\u001b[0m, in \u001b[0;36mLRScheduler.step\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 154\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(EPOCH_DEPRECATION_WARNING, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 55\u001b[0m, in \u001b[0;36mCosineAnnealingLR.get_lr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs) \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epochs)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     51\u001b[0m         group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m (base_lr \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_min) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(math\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epochs))) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m base_lr, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_lrs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups)\n\u001b[1;32m     53\u001b[0m     ]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     56\u001b[0m     (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(math\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epochs) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epochs)))\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(math\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epochs)))\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;241m*\u001b[39m (group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_min)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_min\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups\n\u001b[1;32m     61\u001b[0m ]\n",
      "Cell \u001b[0;32mIn[7], line 56\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs) \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epochs)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     51\u001b[0m         group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m (base_lr \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_min) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(math\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epochs))) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m base_lr, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_lrs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups)\n\u001b[1;32m     53\u001b[0m     ]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m---> 56\u001b[0m     (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241m.\u001b[39mcos(math\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epochs) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epochs)))\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(math\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epochs)))\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;241m*\u001b[39m (group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_min)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_min\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups\n\u001b[1;32m     61\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "curves = []\n",
    "for e in range(max_epoch):\n",
    "    for s in range(iter_step):\n",
    "        # 各イテレーションでパラメータを更新\n",
    "        optimizer.step()\n",
    "        curves += [optimizer.param_groups[0][\"lr\"]]\n",
    "    # 各epoch終了後にスケジューラで最適化学習率を更新\n",
    "    lr_scheduler.step()\n",
    "\n",
    "plt.plot(curves)\n",
    "plt.savefig(\"lr_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arch = 'resnet18'\n",
    "dim_dict = {\n",
    "    'resnet18':512,\n",
    "}\n",
    "dim = dim_dict.get(arch, 1280)\n",
    "\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISIC_5726301.jpg', 'ISIC_4336258.jpg', 'ISIC_1510555.jpg', 'ISIC_0428056.jpg', 'ISIC_8108962.jpg', 'ISIC_8143544.jpg', 'ISIC_2473523.jpg', 'ISIC_1672562.jpg', 'ISIC_9741000.jpg', 'ISIC_3008170.jpg']\n",
      "(137, 137)\n",
      "(131, 131)\n",
      "(109, 109)\n",
      "(121, 121)\n",
      "(137, 137)\n",
      "(117, 117)\n",
      "(127, 127)\n",
      "(169, 169)\n",
      "(113, 113)\n",
      "(141, 141)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "image_path = '/root/Development/Kaggle/ISIC2024/data/raw/train-image/image/'\n",
    "# image_path = 'Development/Kaggle/ISIC2024/main/models'\n",
    "\n",
    "image_list = os.listdir(image_path)\n",
    "image_list_10 = image_list[:10]\n",
    "\n",
    "print(image_list_10)\n",
    "\n",
    "# Open the image file\n",
    "for path in image_list_10:\n",
    "    image = Image.open(image_path + path)\n",
    "    print(image.size)\n",
    "\n",
    "    # # Display the image\n",
    "    # plt.imshow(image)\n",
    "    # plt.axis('off')  # Hide the axis\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (fc): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "\n",
    "# Load the resnet18 model\n",
    "model = timm.create_model('resnet18', pretrained=False, num_classes=0)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.54835175]\n",
      " [ 0.21671934]\n",
      " [ 0.17882353]\n",
      " [-1.88504006]\n",
      " [-0.0975358 ]\n",
      " [ 1.46056303]\n",
      " [ 1.07305814]\n",
      " [ 1.09843883]\n",
      " [ 0.94972329]\n",
      " [-0.94186006]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "logit=0\n",
    "for i in range(1):\n",
    "    logit += np.random.randn(10,1)\n",
    "logit = logit/len('a')\n",
    "\n",
    "print(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0266, -2.0024, -0.7541,  0.0875],\n",
      "        [ 0.6679, -1.3453, -0.5650, -0.4380],\n",
      "        [-1.6116, -0.8948, -0.0234,  2.8518],\n",
      "        [ 0.0050,  0.4251,  0.2849, -1.4315]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5067, 0.1189, 0.3199, 0.5219],\n",
       "        [0.6610, 0.2066, 0.3624, 0.3922],\n",
       "        [0.1664, 0.2901, 0.4942, 0.9454],\n",
       "        [0.5012, 0.6047, 0.5707, 0.1929]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.randn(4,4)\n",
    "print(t)\n",
    "torch.special.expit(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_scheduler(scheduler_class, optimizer_class, scheduler_params, optimizer_params, epochs, option_name=''):\n",
    "    optimizer = optimizer_class([torch.tensor(0.0, requires_grad=True)], **optimizer_params)\n",
    "    scheduler = scheduler_class(optimizer, **scheduler_params)\n",
    "\n",
    "    lr_log = []\n",
    "    for epoch in range(epochs):\n",
    "        lr_log.append(optimizer.param_groups[0]['lr'])\n",
    "        scheduler.step()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(epochs), lr_log)\n",
    "    plt.title(f\"{scheduler_class.__name__} with {optimizer_class.__name__}\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.savefig(f'{scheduler_class.__name__}' + f'{option_name}' + '.png')\n",
    "    plt.show()\n",
    "\n",
    "# LambdaLR\n",
    "plot_scheduler(lr_scheduler.LambdaLR, optim.Adam, {'lr_lambda': lambda epoch: 0.95 ** epoch}, {'lr': 0.1}, 100)\n",
    "\n",
    "# StepLR\n",
    "plot_scheduler(lr_scheduler.StepLR, optim.Adam, {'step_size': 10, 'gamma': 0.8}, {'lr': 0.1}, 100)\n",
    "\n",
    "# MultiStepLR\n",
    "plot_scheduler(lr_scheduler.MultiStepLR, optim.Adam, {'milestones': [30, 80], 'gamma': 0.1}, {'lr': 0.1}, 100)\n",
    "\n",
    "# ExponentialLR\n",
    "plot_scheduler(lr_scheduler.ExponentialLR, optim.Adam, {'gamma': 0.95}, {'lr': 0.1}, 100)\n",
    "\n",
    "# CosineAnnealingLR\n",
    "plot_scheduler(lr_scheduler.CosineAnnealingLR, optim.Adam, {'T_max': 20, 'eta_min': 0.001}, {'lr': 0.1}, 100)\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "optimizer = optim.Adam([torch.tensor(0.0, requires_grad=True)], lr=0.1)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "lr_log = []\n",
    "for epoch in range(100):\n",
    "    lr_log.append(optimizer.param_groups[0]['lr'])\n",
    "    scheduler.step(epoch)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(100), lr_log)\n",
    "plt.title(\"ReduceLROnPlateau with Adam\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.savefig('ReduceLROnPlateau.png')\n",
    "plt.show()\n",
    "\n",
    "# CyclicLR-triangular\n",
    "plot_scheduler(lr_scheduler.CyclicLR, optim.SGD, {'base_lr': 0.001, 'max_lr': 0.1, 'step_size_up': 20, 'mode': 'triangular'}, {'lr': 0.1, 'momentum': 0.9}, 100, '-1')\n",
    "\n",
    "# CyclicLR-triangular2\n",
    "plot_scheduler(lr_scheduler.CyclicLR, optim.SGD, {'base_lr': 0.001, 'max_lr': 0.1, 'step_size_up': 20, 'mode': 'triangular2'}, {'lr': 0.1, 'momentum': 0.9}, 100, '-2')\n",
    "\n",
    "# CyclicLR-exp_range\n",
    "plot_scheduler(lr_scheduler.CyclicLR, optim.SGD, {'base_lr': 0.001, 'max_lr': 0.1, 'step_size_up': 20, 'mode': 'exp_range', 'gamma': 0.95}, {'lr': 0.1, 'momentum': 0.9}, 100, '-exp')\n",
    "\n",
    "# OneCycleLR\n",
    "plot_scheduler(lr_scheduler.OneCycleLR, optim.SGD, {'max_lr': 0.1, 'total_steps': 100, 'pct_start': 0.3, 'anneal_strategy': 'cos'}, {'lr': 0.1, 'momentum': 0.9}, 100)\n",
    "\n",
    "# CosineAnnealingWarmRestarts\n",
    "plot_scheduler(lr_scheduler.CosineAnnealingWarmRestarts, optim.Adam, {'T_0':10}, {'lr': 0.1}, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load a sample dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='viridis')\n",
    "plt.colorbar(scatter)\n",
    "plt.title('t-SNE visualization of the Digits dataset')\n",
    "plt.savefig('/root/Development/Kaggle/ISIC2024/reports/figures/t-SNE_digits.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load a sample dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Perform PCA for initialization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# t-SNE with PCA initialization\n",
    "tsne_pca = TSNE(n_components=2, init='pca', perplexity=30, n_iter=300)\n",
    "X_tsne_pca = tsne_pca.fit_transform(X)\n",
    "\n",
    "# t-SNE with random initialization\n",
    "tsne_random = TSNE(n_components=2, init='random', perplexity=30, n_iter=300)\n",
    "X_tsne_random = tsne_random.fit_transform(X)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter_pca = plt.scatter(X_tsne_pca[:, 0], X_tsne_pca[:, 1], c=y, cmap='viridis')\n",
    "plt.title('t-SNE with PCA Initialization')\n",
    "plt.colorbar(scatter_pca)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter_random = plt.scatter(X_tsne_random[:, 0], X_tsne_random[:, 1], c=y, cmap='viridis')\n",
    "plt.title('t-SNE with Random Initialization')\n",
    "plt.colorbar(scatter_random)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import time\n",
    "\n",
    "# Load a sample dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Perform PCA\n",
    "start_time = time.time()\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "pca_time = time.time() - start_time\n",
    "\n",
    "# Perform t-SNE with PCA initialization\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, init='pca', perplexity=30, n_iter=300)\n",
    "X_tsne_pca = tsne.fit_transform(X)\n",
    "tsne_time = time.time() - start_time\n",
    "\n",
    "# Perform UMAP\n",
    "start_time = time.time()\n",
    "umap_reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = umap_reducer.fit_transform(X)\n",
    "umap_time = time.time() - start_time\n",
    "\n",
    "# Perform DensMAP (Densified Manifold Approximation and Projection)\n",
    "start_time = time.time()\n",
    "densmap_reducer = umap.UMAP(densmap=True, random_state=42)\n",
    "X_densmap = densmap_reducer.fit_transform(X)\n",
    "densmap_time = time.time() - start_time\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "scatter_pca = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', s=5)\n",
    "plt.title(f'PCA (time: {pca_time:.2f} s)')\n",
    "plt.colorbar(scatter_pca)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "scatter_tsne_pca = plt.scatter(X_tsne_pca[:, 0], X_tsne_pca[:, 1], c=y, cmap='viridis', s=5)\n",
    "plt.title(f't-SNE (time: {tsne_time:.2f} s)')\n",
    "plt.colorbar(scatter_tsne_pca)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "scatter_umap = plt.scatter(X_umap[:, 0], X_umap[:, 1], c=y, cmap='viridis', s=5)\n",
    "plt.title(f'UMAP (time: {umap_time:.2f} s)')\n",
    "plt.colorbar(scatter_umap)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "scatter_densmap = plt.scatter(X_densmap[:, 0], X_densmap[:, 1], c=y, cmap='viridis', s=5)\n",
    "plt.title(f'DensMAP (time: {densmap_time:.2f} s)')\n",
    "plt.colorbar(scatter_densmap)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/root/Development/Kaggle/ISIC2024/reports/figures/compare_RD_methods')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import time\n",
    "\n",
    "# Load a sample dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Perform PCA\n",
    "start_time = time.time()\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "pca_time = time.time() - start_time\n",
    "\n",
    "# Perform t-SNE with PCA initialization\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, init='pca', perplexity=30, n_iter=300)\n",
    "X_tsne_pca = tsne.fit_transform(X)\n",
    "tsne_time = time.time() - start_time\n",
    "\n",
    "# Perform UMAP\n",
    "start_time = time.time()\n",
    "umap_reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = umap_reducer.fit_transform(X)\n",
    "umap_time = time.time() - start_time\n",
    "\n",
    "# Perform DensMAP (Densified Manifold Approximation and Projection)\n",
    "start_time = time.time()\n",
    "densmap_reducer = umap.UMAP(densmap=True, random_state=42)\n",
    "X_densmap = densmap_reducer.fit_transform(X)\n",
    "densmap_time = time.time() - start_time\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.imshow(digits.images[0], cmap='gray')\n",
    "plt.title('Sample Image 1')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.imshow(digits.images[1], cmap='gray')\n",
    "plt.title('Sample Image 2')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "scatter_pca = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', s=5)\n",
    "plt.title(f'PCA (time: {pca_time:.2f} s)')\n",
    "plt.colorbar(scatter_pca)\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "scatter_tsne_pca = plt.scatter(X_tsne_pca[:, 0], X_tsne_pca[:, 1], c=y, cmap='viridis', s=5)\n",
    "plt.title(f't-SNE with PCA Initialization (time: {tsne_time:.2f} s)')\n",
    "plt.colorbar(scatter_tsne_pca)\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "scatter_umap = plt.scatter(X_umap[:, 0], X_umap[:, 1], c=y, cmap='viridis', s=5)\n",
    "plt.title(f'UMAP (time: {umap_time:.2f} s)')\n",
    "plt.colorbar(scatter_umap)\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "scatter_densmap = plt.scatter(X_densmap[:, 0], X_densmap[:, 1], c=y, cmap='viridis', s=5)\n",
    "plt.title(f'DensMAP (time: {densmap_time:.2f} s)')\n",
    "plt.colorbar(scatter_densmap)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load the dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "images = digits.images\n",
    "\n",
    "# Display all the input patterns\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.title(f'Digit: {y[i]}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Input Patterns')\n",
    "plt.savefig('/root/Development/Kaggle/ISIC2024/reports/figures/inputs.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import time\n",
    "\n",
    "# Load a sample dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Perform PCA\n",
    "start_time = time.time()\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "pca_time = time.time() - start_time\n",
    "\n",
    "# Perform t-SNE with PCA initialization\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, init='pca', perplexity=30, n_iter=300)\n",
    "X_tsne_pca = tsne.fit_transform(X)\n",
    "tsne_time = time.time() - start_time\n",
    "\n",
    "# Perform UMAP\n",
    "start_time = time.time()\n",
    "umap_reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = umap_reducer.fit_transform(X)\n",
    "umap_time = time.time() - start_time\n",
    "\n",
    "# Perform DensMAP (Densified Manifold Approximation and Projection)\n",
    "start_time = time.time()\n",
    "densmap_reducer = umap.UMAP(densmap=True, random_state=42)\n",
    "X_densmap = densmap_reducer.fit_transform(X)\n",
    "densmap_time = time.time() - start_time\n",
    "\n",
    "# Plotting the results one by one\n",
    "plt.figure()\n",
    "scatter_pca = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', s=5)\n",
    "plt.title(f'PCA (time: {pca_time:.2f} s)')\n",
    "plt.colorbar(scatter_pca)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "scatter_tsne_pca = plt.scatter(X_tsne_pca[:, 0], X_tsne_pca[:, 1], c=y, cmap='viridis', s=5)\n",
    "plt.title(f't-SNE (time: {tsne_time:.2f} s)')\n",
    "plt.colorbar(scatter_tsne_pca)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "scatter_umap = plt.scatter(X_umap[:, 0], X_umap[:, 1], c=y, cmap='viridis', s=5)\n",
    "plt.title(f'UMAP (time: {umap_time:.2f} s)')\n",
    "plt.colorbar(scatter_umap)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "scatter_densmap = plt.scatter(X_densmap[:, 0], X_densmap[:, 1], c=y, cmap='viridis', s=5)\n",
    "plt.title(f'DensMAP (time: {densmap_time:.2f} s)')\n",
    "plt.colorbar(scatter_densmap)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
