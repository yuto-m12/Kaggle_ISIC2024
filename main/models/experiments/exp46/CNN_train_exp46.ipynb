{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import typing as tp\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import timm\n",
    "from time import time\n",
    "from tqdm.notebook import tqdm\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "\n",
    "import optuna\n",
    "import wandb\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import amp\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \n",
    "    exp = 46\n",
    "    \n",
    "    is_kaggle = False\n",
    "    is_infer = True\n",
    "    enable_wandb = False\n",
    "    if is_kaggle:\n",
    "        OUTPUT_DIR = Path('/kaggle/input/isic2024-baseline')\n",
    "        TRAIN_DIR = Path('/kaggle/input/isic-2024-challenge/train-image/image')\n",
    "        TRAIN_HDF5 = Path('/kaggle/input/isic-2024-challenge/train-image.hdf5')\n",
    "        TEST_HDF5 = Path('/kaggle/input/isic-2024-challenge/test-image.hdf5')\n",
    "        TRAIN_META = Path('/kaggle/input/isic-2024-challenge/train-metadata.csv')\n",
    "        TEST_META = Path('/kaggle/input/isic-2024-challenge/test-metadata.csv')\n",
    "        SAMPLE_SUB = Path('/kaggle/input/isic-2024-challenge/sample_submission.csv')\n",
    "        PRETRAINED_MODEL = ''\n",
    "        \n",
    "    else:\n",
    "        OUTPUT_DIR = Path(f'/root/Development/Kaggle/ISIC2024/main/models/experiments/exp{exp}/outputs')\n",
    "        OUTPUT_LOG = Path(f'/root/Development/Kaggle/ISIC2024/main/models/experiments/exp{exp}/log.txt')\n",
    "        TRAIN_DIR = Path('/root/Development/Kaggle/ISIC2024/data/raw/train-image/image')\n",
    "        TRAIN_HDF5 = Path('/root/Development/Kaggle/ISIC2024/data/raw/train-image.hdf5')\n",
    "        TEST_HDF5 = Path('/root/Development/Kaggle/ISIC2024/data/raw/test-image.hdf5')\n",
    "        TRAIN_META = Path('/root/Development/Kaggle/ISIC2024/data/raw/train-metadata.csv')\n",
    "        TEST_META = Path('/root/Development/Kaggle/ISIC2024/data/raw/test-metadata.csv')\n",
    "        SAMPLE_SUB = Path('/root/Development/Kaggle/ISIC2024/data/raw/sample_submission.csv')\n",
    "        TRAIN_META_ADD = Path('/root/Development/Kaggle/ISIC2024/data/external/All/metadata.csv')\n",
    "        TRAIN_HDF5_ADD = Path('/root/Development/Kaggle/ISIC2024/data/external/All/image.hdf5')\n",
    "        TRAIN_HDF5_COMBINED = Path('/root/Development/Kaggle/ISIC2024/data/processed/train-image-combined.hdf5')\n",
    "        # PRETRAINED_MODEL = ''\n",
    "        PRETRAINED_MODEL = Path('/root/Development/Kaggle/ISIC2024/main/models/experiments/exp32/outputs/averaged_model.pth')\n",
    "    \n",
    "    es_patience = 5\n",
    "    batch_size = 128 # 256\n",
    "    max_epoch = 9\n",
    "    n_folds = 5\n",
    "    n_classes = 2\n",
    "    random_seed = 42\n",
    "    lr = 1.0e-04 # lr = 1.0e-03\n",
    "    weight_decay = 1.0e-02 # default\n",
    "    deterministic = True\n",
    "    enable_amp = True\n",
    "    view = True\n",
    "    change_dataset = True\n",
    "    standardization = True\n",
    "    oversampling = False\n",
    "    oversampling_percent = 3\n",
    "    only_lesion_id = False\n",
    "    alldata_isic_archive = False\n",
    "    test_of_averaged_model = False\n",
    "    train_with_fewdata: int|bool = False\n",
    "    # train_with_fewdata: int|bool = 100000 # or False\n",
    "    pretrained = True\n",
    "    TTA: bool = True\n",
    "    TTA_rate = {'None':0.7, 'with_train_aug':0.3}\n",
    "    AUX_LOSS = False\n",
    "    use_tabler = True\n",
    "    image_pred_as_tabler_feature = False\n",
    "    ensemble_image_table = True\n",
    "    \n",
    "    model_name = 'maxvit_rmlp_pico_rw_256.sw_in1k'\n",
    "    output_dim_models = { \n",
    "        \"resnet18.a1_in1k\": 512,\n",
    "        \"efficientnet_b0.ra_in1k\": 320,\n",
    "        \"tf_efficientnet_b0.ns_jft_in1k\": 1280,\n",
    "        # 'tf_efficientnet_b5.ns_jft_in1k': 1280,\n",
    "        'tf_efficientnet_b3.ns_jft_in1k': 1536,\n",
    "        'eva02_large_patch14_224.mim_in22k': 384,\n",
    "        'eva02_large_patch14_448.mim_m38m_ft_in22k_in1k': 384,\n",
    "        'maxvit_tiny_tf_224.in1k': 256,\n",
    "        'maxvit_rmlp_nano_rw_256.sw_in1k': 256,\n",
    "        'maxvit_rmlp_pico_rw_256.sw_in1k': 256,\n",
    "        'maxvit_small_tf_224.in1k': 256,\n",
    "    }\n",
    "    \n",
    "    # img_size = 224\n",
    "    img_size = 256\n",
    "    # img_size = 384\n",
    "    interpolation = cv2.INTER_LINEAR\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        \n",
    "    \n",
    "    wandb_config = {\n",
    "    \"es_patience\" : es_patience,\n",
    "    \"batch_size\" : batch_size, # 128 # 256\n",
    "    \"max_epoch\" : max_epoch,\n",
    "    \"n_folds\" : n_folds,\n",
    "    \"n_classes\" : n_classes,\n",
    "    \"random_seed\" : random_seed,\n",
    "    \"lr\" : lr, # lr = 1.0e-04\n",
    "    \"weight_decay\" : weight_decay, # default\n",
    "    \"deterministic\" : deterministic,\n",
    "    \"enable_amp\" : enable_amp,\n",
    "    \"view\" : view,\n",
    "    \"change_dataset\" : change_dataset,\n",
    "    \"standardization\" : standardization,\n",
    "    \"oversampling\" : oversampling,\n",
    "    \"oversampling_percent\" : oversampling_percent,\n",
    "    \"only_lesion_id\" : only_lesion_id,\n",
    "    \"alldata_isic_archive\" : alldata_isic_archive,\n",
    "    \"test_of_averaged_model\" : test_of_averaged_model,\n",
    "    \"train_with_fewdata\" : train_with_fewdata, # 100000 or False\n",
    "    \"pretrained\" : pretrained,\n",
    "    \"TTA\" : TTA,\n",
    "    \"TTA_rate\" : TTA_rate,\n",
    "    \"model_name\" : model_name,\n",
    "    \"output_dim_models\" : output_dim_models,\n",
    "    \"img_size\" : img_size, # 224 # 256 # 384\n",
    "    \"interpolation\" : interpolation,\n",
    "    \"AUX_LOSS\" : AUX_LOSS,\n",
    "    \"use_tabler\": use_tabler,\n",
    "    \"image_pred_as_tabler_feature\": image_pred_as_tabler_feature,\n",
    "    \"ensemble_image_table\": ensemble_image_table,\n",
    "    }\n",
    "    if enable_wandb:\n",
    "        wandb.login()\n",
    "        run = wandb.init(project=\"ISIC2024\", name=f\"experiment_{exp}\", config=wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_meta = pd.read_csv(CFG.TRAIN_META)\n",
    "test_meta = pd.read_csv(CFG.TEST_META)\n",
    "print(len(train_meta))\n",
    "print(len(test_meta))\n",
    "\n",
    "# head\n",
    "display(train_meta[train_meta['target'] > 0.5].head(10))\n",
    "display(train_meta.head())\n",
    "display(test_meta.head())\n",
    "\n",
    "\n",
    "if not CFG.is_infer:\n",
    "    train_meta_add = pd.read_csv(CFG.TRAIN_META_ADD)\n",
    "    print(len(train_meta_add))\n",
    "    display(train_meta_add.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    # only benign or maligant\n",
    "    train_meta_add = train_meta_add[train_meta_add['benign_malignant'].isin(['benign', 'malignant'])]\n",
    "    # make the target column\n",
    "    train_meta_add['target'] = train_meta_add['benign_malignant'].apply(lambda x: 1 if x == 'malignant' else 0)\n",
    "    # assign difference patientid\n",
    "    train_meta_add['patient_id'] = [\n",
    "        f\"example_{i+1}\" if pd.isna(id) else id\n",
    "        for i, id in enumerate(train_meta_add['patient_id'])\n",
    "    ]\n",
    "\n",
    "    train_meta_add['additional'] = 1\n",
    "\n",
    "    display(train_meta_add.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    # delete clothes and others\n",
    "    # List of IDs to drop\n",
    "    ids_to_drop = ['ISIC_0573025', 'ISIC_1443812', 'ISIC_5374420', 'ISIC_2611119', 'ISIC_2691718', 'ISIC_9689783', 'ISIC_9520696', 'ISIC_8651165', 'ISIC_9385142', 'ISIC_9680590']\n",
    "    train_meta = train_meta.drop(train_meta[train_meta['isic_id'].isin(ids_to_drop)].index)\n",
    "    train_meta = train_meta.reset_index(drop=True)\n",
    "\n",
    "    if CFG.train_with_fewdata:\n",
    "        filtered_train_meta = train_meta[train_meta['lesion_id'].notnull()]\n",
    "        print(\"len filtered_train_meta: \", len(filtered_train_meta))\n",
    "\n",
    "        # Select 100 rows from the remaining DataFrame\n",
    "        remaining_rows = train_meta[~train_meta.index.isin(filtered_train_meta.index)]\n",
    "        selected_rows = remaining_rows.sample(n=CFG.train_with_fewdata - len(filtered_train_meta), random_state=CFG.random_seed).reset_index(drop=True)\n",
    "\n",
    "        # Combine both DataFrames\n",
    "        combined_df = pd.concat([filtered_train_meta, selected_rows]).reset_index(drop=True)\n",
    "        train_meta = combined_df\n",
    "\n",
    "    # only has lesion_id(strgong label)\n",
    "    if CFG.only_lesion_id:\n",
    "        train_meta = train_meta[train_meta['lesion_id'].notnull()].reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # add \"additional\" column\n",
    "    train_meta['additional'] = 0\n",
    "\n",
    "    print(len(train_meta))\n",
    "    print(len(train_meta[train_meta['target']==1]))\n",
    "    print(len(train_meta[train_meta['target']==1]) / len(train_meta) * 100, '%')\n",
    "    display(train_meta.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat both data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    concatenated = pd.concat([train_meta, train_meta_add], axis=0)\n",
    "    if CFG.alldata_isic_archive:\n",
    "        train_meta = concatenated.reset_index(drop=True)\n",
    "        display(train_meta.head())\n",
    "        display(train_meta.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split to fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "\n",
    "    def split_fold(df:pd.DataFrame):\n",
    "        # if 'fold' in df.columns:\n",
    "        #     return df\n",
    "        \n",
    "        df['fold'] = -1\n",
    "        # object\n",
    "        skf = StratifiedGroupKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.random_seed)\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df, df['target'], df['patient_id'])):\n",
    "            df.loc[test_index, 'fold'] = i\n",
    "        \n",
    "        return df\n",
    "            \n",
    "    train_meta = split_fold(train_meta)\n",
    "    display(train_meta.head().T)\n",
    "\n",
    "    # check\n",
    "    if CFG.view:\n",
    "        print(train_meta.groupby('fold')['target'].value_counts().head(300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "    if CFG.oversampling:\n",
    "\n",
    "        percent = CFG.oversampling_percent\n",
    "\n",
    "        train_meta_mali = train_meta[train_meta['target']==1]\n",
    "        for _ in range(100):\n",
    "            train_meta = pd.concat([train_meta, train_meta_mali], axis=0)\n",
    "            if len(train_meta[train_meta['target']==1]) / len(train_meta) * 100 >= percent:\n",
    "                print(f'over {percent}% malignant')\n",
    "                break\n",
    "\n",
    "        print(len(train_meta))\n",
    "        print(len(train_meta[train_meta['target']==1]))\n",
    "        print(len(train_meta[train_meta['target']==1]) / len(train_meta) * 100, '%')\n",
    "\n",
    "        del percent\n",
    "\n",
    "        if CFG.view:\n",
    "            print(train_meta.groupby('fold')['target'].value_counts().head(300))\n",
    "            display(train_meta.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Tabler Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'isic_id'\n",
    "target_col = 'target'\n",
    "group_col = 'patient_id'\n",
    "\n",
    "err = 1e-5\n",
    "sampling_ratio = 0.01\n",
    "seed = 42\n",
    "\n",
    "num_cols = [\n",
    "    'age_approx',                        # Approximate age of patient at time of imaging.\n",
    "    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n",
    "    'tbp_lv_A',                          # A inside  lesion.+\n",
    "    'tbp_lv_Aext',                       # A outside lesion.+\n",
    "    'tbp_lv_B',                          # B inside  lesion.+\n",
    "    'tbp_lv_Bext',                       # B outside lesion.+ \n",
    "    'tbp_lv_C',                          # Chroma inside  lesion.+\n",
    "    'tbp_lv_Cext',                       # Chroma outside lesion.+\n",
    "    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n",
    "    'tbp_lv_Hext',                       # Hue outside lesion.+\n",
    "    'tbp_lv_L',                          # L inside lesion.+\n",
    "    'tbp_lv_Lext',                       # L outside lesion.+\n",
    "    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n",
    "    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n",
    "    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n",
    "    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaLB',                    #\n",
    "    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n",
    "    'tbp_lv_eccentricity',               # Eccentricity.+\n",
    "    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n",
    "    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n",
    "    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n",
    "    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n",
    "    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n",
    "    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n",
    "    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n",
    "    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n",
    "    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n",
    "    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n",
    "    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n",
    "    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n",
    "    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n",
    "]\n",
    "\n",
    "new_num_cols = [\n",
    "    'lesion_size_ratio',             # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n",
    "    'lesion_shape_index',            # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n",
    "    'hue_contrast',                  # tbp_lv_H                - tbp_lv_Hext              abs\n",
    "    'luminance_contrast',            # tbp_lv_L                - tbp_lv_Lext              abs\n",
    "    'lesion_color_difference',       # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n",
    "    'border_complexity',             # tbp_lv_norm_border      + tbp_lv_symm_2axis\n",
    "    'color_uniformity',              # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n",
    "\n",
    "    'position_distance_3d',          # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n",
    "    'perimeter_to_area_ratio',       # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n",
    "    'area_to_perimeter_ratio',       # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n",
    "    'lesion_visibility_score',       # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n",
    "    'symmetry_border_consistency',   # tbp_lv_symm_2axis       * tbp_lv_norm_border\n",
    "    'consistency_symmetry_border',   # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n",
    "\n",
    "    'color_consistency',             # tbp_lv_stdL             / tbp_lv_Lext\n",
    "    'consistency_color',             # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n",
    "    'size_age_interaction',          # clin_size_long_diam_mm  * age_approx\n",
    "    'hue_color_std_interaction',     # tbp_lv_H                * tbp_lv_color_std_mean\n",
    "    'lesion_severity_index',         # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n",
    "    'shape_complexity_index',        # border_complexity       + lesion_shape_index\n",
    "    'color_contrast_index',          # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n",
    "\n",
    "    'log_lesion_area',               # tbp_lv_areaMM2          + 1  np.log\n",
    "    'normalized_lesion_size',        # clin_size_long_diam_mm  / age_approx\n",
    "    'mean_hue_difference',           # tbp_lv_H                + tbp_lv_Hext    / 2\n",
    "    'std_dev_contrast',              # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n",
    "    'color_shape_composite_index',   # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n",
    "    'lesion_orientation_3d',         # tbp_lv_y                , tbp_lv_x  np.arctan2\n",
    "    'overall_color_difference',      # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n",
    "\n",
    "    'symmetry_perimeter_interaction',# tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n",
    "    'comprehensive_lesion_index',    # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n",
    "    'color_variance_ratio',          # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n",
    "    'border_color_interaction',      # tbp_lv_norm_border      * tbp_lv_norm_color\n",
    "    'border_color_interaction_2',\n",
    "    'size_color_contrast_ratio',     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n",
    "    'age_normalized_nevi_confidence',# tbp_lv_nevi_confidence  / age_approx\n",
    "    'age_normalized_nevi_confidence_2',\n",
    "    'color_asymmetry_index',         # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n",
    "\n",
    "    'volume_approximation_3d',       # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n",
    "    'color_range',                   # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n",
    "    'shape_color_consistency',       # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n",
    "    'border_length_ratio',           # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n",
    "    'age_size_symmetry_index',       # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n",
    "    'index_age_size_symmetry',       # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n",
    "]\n",
    "\n",
    "cat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'attribution']\n",
    "norm_cols = [f'{col}_patient_norm' for col in num_cols + new_num_cols]\n",
    "special_cols = ['count_per_patient']\n",
    "feature_cols = num_cols + new_num_cols + cat_cols + norm_cols + special_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Read CSV and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recieve pd.df and creating feature columns in pl\n",
    "def read_data(pd_df:pd.DataFrame):\n",
    "    return (\n",
    "        pl.from_pandas(pd_df)\n",
    "        .with_columns(\n",
    "            pl.col('age_approx').cast(pl.String).replace('NA', np.nan).cast(pl.Float64),\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(pl.Float64).fill_nan(pl.col(pl.Float64).median()), # You may want to impute test data with train\n",
    "        )\n",
    "        .with_columns(\n",
    "            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n",
    "            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n",
    "            hue_contrast                   = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n",
    "            luminance_contrast             = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n",
    "            lesion_color_difference        = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n",
    "            border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n",
    "            color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n",
    "        )\n",
    "        .with_columns(\n",
    "            position_distance_3d           = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n",
    "            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n",
    "            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n",
    "            lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n",
    "            combined_anatomical_site       = pl.col('anatom_site_general') + '_' + pl.col('tbp_lv_location'),\n",
    "            symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n",
    "            consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n",
    "        )\n",
    "        .with_columns(\n",
    "            color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n",
    "            consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n",
    "            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n",
    "            hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n",
    "            lesion_severity_index          = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n",
    "            shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n",
    "            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n",
    "        )\n",
    "        .with_columns(\n",
    "            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n",
    "            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n",
    "            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n",
    "            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n",
    "            color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n",
    "            lesion_orientation_3d          = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n",
    "            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n",
    "        )\n",
    "        .with_columns(\n",
    "            symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n",
    "            comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n",
    "            color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n",
    "            border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n",
    "            border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n",
    "            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n",
    "            age_normalized_nevi_confidence = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n",
    "            age_normalized_nevi_confidence_2 = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n",
    "            color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n",
    "        )\n",
    "        .with_columns(\n",
    "            volume_approximation_3d        = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n",
    "            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n",
    "            shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n",
    "            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n",
    "            age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n",
    "            index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n",
    "        )\n",
    "        # .with_columns(\n",
    "        #     ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols + new_num_cols)\n",
    "        # )\n",
    "        .with_columns(\n",
    "            count_per_patient = pl.col('isic_id').count().over('patient_id'),\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(cat_cols).cast(pl.Categorical),\n",
    "        )\n",
    "        .to_pandas()\n",
    "        # .set_index(id_col)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical features for models that can't handle is as is. \n",
    "def preprocess(df_train, df_test):\n",
    "    global cat_cols\n",
    "    \n",
    "    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n",
    "    encoder.fit(df_train[cat_cols])\n",
    "    \n",
    "    new_cat_cols = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n",
    "\n",
    "    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n",
    "    df_train[new_cat_cols] = df_train[new_cat_cols].astype('category')\n",
    "\n",
    "    df_test[new_cat_cols] = encoder.transform(df_test[cat_cols])\n",
    "    df_test[new_cat_cols] = df_test[new_cat_cols].astype('category')\n",
    "\n",
    "    for col in cat_cols:\n",
    "        feature_cols.remove(col)\n",
    "\n",
    "    feature_cols.extend(new_cat_cols)\n",
    "    cat_cols = new_cat_cols\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Custom metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(estimator, X, y_true):\n",
    "    y_hat = estimator.predict_proba(X)[:, 1]\n",
    "    min_tpr = 0.80\n",
    "    max_fpr = abs(1 - min_tpr)\n",
    "    \n",
    "    v_gt = abs(y_true - 1)\n",
    "    v_pred = np.array([1.0 - x for x in y_hat])\n",
    "    \n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    \n",
    "    return partial_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .with_columns(\n",
    "#     ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols + new_num_cols)\n",
    "# )\n",
    "\n",
    "# preprocess\n",
    "df_train = read_data(train_meta)\n",
    "new_columns = {}\n",
    "for col in num_cols + new_num_cols:\n",
    "    patient_mean = df_train.groupby('patient_id')[col].transform('mean')\n",
    "    patient_std = df_train.groupby('patient_id')[col].transform('std')\n",
    "    # Store the normalized column in the dictionary\n",
    "    new_columns[f'{col}_patient_norm'] = (df_train[col] - patient_mean) / (patient_std + err)\n",
    "df_train = pd.concat([df_train, pd.DataFrame(new_columns)], axis=1)\n",
    "\n",
    "\n",
    "# preprocess\n",
    "df_test = read_data(test_meta)\n",
    "new_columns = {}\n",
    "for col in num_cols + new_num_cols:\n",
    "    patient_mean_test = df_test.groupby('patient_id')[col].transform('mean')\n",
    "    patient_std_test = df_test.groupby('patient_id')[col].transform('std')\n",
    "    # Store the normalized column in the dictionary\n",
    "    new_columns[f'{col}_patient_norm'] = (df_test[col] - patient_mean_test) / (patient_std_test + err)\n",
    "df_test = pd.concat([df_test, pd.DataFrame(new_columns)], axis=1)\n",
    "\n",
    "df_subm = pd.read_csv(CFG.SAMPLE_SUB, index_col=id_col)\n",
    "\n",
    "# dealing categorical data\n",
    "df_train, df_test = preprocess(df_train, df_test)\n",
    "\n",
    "train_meta = df_train\n",
    "test_meta = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_meta.shape)\n",
    "print(test_meta.shape)\n",
    "\n",
    "display(train_meta.head())\n",
    "display(test_meta.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed in each env\n",
    "def set_random_seed(seed: int = 42, deterministic: bool = False):\n",
    "    \"\"\"Set seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n",
    "\n",
    "# function to set tensor to device\n",
    "def to_device(\n",
    "    tensors: tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]],\n",
    "    device: torch.device, *args, **kwargs\n",
    "):\n",
    "    if isinstance(tensors, tuple):\n",
    "        return (t.to(device, *args, **kwargs) for t in tensors)\n",
    "    elif isinstance(tensors, dict):\n",
    "        return {\n",
    "            k: t.to(device, *args, **kwargs) for k, t in tensors.items()}\n",
    "    else:\n",
    "        return tensors.to(device, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_transforms(include_light=False):\n",
    "    augmentations_train = A.Compose([\n",
    "    A.Transpose(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, p=0.3),\n",
    "    A.OneOf([\n",
    "            A.MotionBlur(blur_limit=5, p=0.5),\n",
    "            A.MedianBlur(blur_limit=5, p=0.5),\n",
    "            A.GaussianBlur(blur_limit=5, p=0.5),\n",
    "        ], p=0.2),\n",
    "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.1),\n",
    "    # A.OpticalDistortion(distort_limit=0.5, p=0.3),\n",
    "    # A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.3),\n",
    "    # A.ElasticTransform(alpha=1, p=0.3),\n",
    "    # A.CLAHE(clip_limit=2.0, p=0.3),\n",
    "    # A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=5, p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.3),\n",
    "    A.CoarseDropout(max_holes=20, min_holes=10, p=0.3),\n",
    "    A.Resize(CFG.img_size, CFG.img_size),\n",
    "    # A.Normalize(\n",
    "    #                 mean=[0.485, 0.456, 0.406], \n",
    "    #                 std=[0.229, 0.224, 0.225], \n",
    "    #                 max_pixel_value=255.0, \n",
    "    #                 p=1.0\n",
    "    #             ),\n",
    "    ToTensorV2(p=1)\n",
    "    ])\n",
    "    augmentations_train_light = A.Compose([\n",
    "        A.Transpose(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, p=0.1),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(blur_limit=5, p=0.5),\n",
    "            A.MedianBlur(blur_limit=5, p=0.5),\n",
    "            A.GaussianBlur(blur_limit=5, p=0.5),\n",
    "        ], p=0.1),\n",
    "        # A.GaussNoise(var_limit=(5.0, 30.0), p=0.5),\n",
    "        # A.OpticalDistortion(distort_limit=0.5, p=0.5),\n",
    "        # A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
    "        # A.ElasticTransform(alpha=1, p=0.5),\n",
    "        # A.CLAHE(clip_limit=2.0, p=0.5),\n",
    "        # A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=5, p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.2),\n",
    "        A.CoarseDropout(max_holes=30, min_holes=20, p=0.2),\n",
    "        A.Resize(CFG.img_size, CFG.img_size),\n",
    "        # A.Normalize(\n",
    "        #                 mean=[0.485, 0.456, 0.406], \n",
    "        #                 std=[0.229, 0.224, 0.225], \n",
    "        #                 max_pixel_value=255.0, \n",
    "        #                 p=1.0\n",
    "        #             ),\n",
    "        ToTensorV2(p=1)\n",
    "    ])\n",
    "    \n",
    "    augmentations_test = A.Compose([\n",
    "        A.Resize(CFG.img_size, CFG.img_size),\n",
    "        # A.Normalize(\n",
    "        #                 mean=[0.485, 0.456, 0.406], \n",
    "        #                 std=[0.229, 0.224, 0.225], \n",
    "        #                 max_pixel_value=255.0, \n",
    "        #                 p=1.0\n",
    "        #             ),\n",
    "        ToTensorV2(p=1)\n",
    "    ])\n",
    "    if include_light:\n",
    "        return augmentations_train, augmentations_test, augmentations_train_light\n",
    "    return augmentations_train, augmentations_test\n",
    "\n",
    "# def get_transforms():\n",
    "#     data_transforms = {\n",
    "#         \"train\": A.Compose([\n",
    "#             A.Resize(CFG.img_size, CFG.img_size),\n",
    "#             A.RandomRotate90(p=0.5),\n",
    "#             A.Flip(p=0.5),\n",
    "#             A.Downscale(p=0.25),\n",
    "#             A.ShiftScaleRotate(shift_limit=0.1, \n",
    "#                             scale_limit=0.15, \n",
    "#                             rotate_limit=60, \n",
    "#                             p=0.5),\n",
    "#             A.HueSaturationValue(\n",
    "#                     hue_shift_limit=0.2, \n",
    "#                     sat_shift_limit=0.2, \n",
    "#                     val_shift_limit=0.2, \n",
    "#                     p=0.5\n",
    "#                 ),\n",
    "#             A.RandomBrightnessContrast(\n",
    "#                     brightness_limit=(-0.1,0.1), \n",
    "#                     contrast_limit=(-0.1, 0.1), \n",
    "#                     p=0.5\n",
    "#                 ),\n",
    "#             A.Normalize(\n",
    "#                     mean=[0.485, 0.456, 0.406], \n",
    "#                     std=[0.229, 0.224, 0.225], \n",
    "#                     max_pixel_value=255.0, \n",
    "#                     p=1.0\n",
    "#                 ),\n",
    "#             ToTensorV2()], p=1.),\n",
    "        \n",
    "#         \"valid\": A.Compose([\n",
    "#             A.Resize(CFG.img_size, CFG.img_size),\n",
    "#             A.Normalize(\n",
    "#                     mean=[0.485, 0.456, 0.406], \n",
    "#                     std=[0.229, 0.224, 0.225], \n",
    "#                     max_pixel_value=255.0, \n",
    "#                     p=1.0\n",
    "#                 ),\n",
    "#             ToTensorV2()], p=1.)\n",
    "#     }\n",
    "#     return data_transforms[\"train\"], data_transforms[\"valid\"]\n",
    "\n",
    "# def get_transforms():\n",
    "#     train_transforms = A.Compose([\n",
    "#         A.Transpose(p=0.5),\n",
    "#         A.VerticalFlip(p=0.5),\n",
    "#         A.HorizontalFlip(p=0.5),\n",
    "#         A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.75),\n",
    "#         A.OneOf([\n",
    "#             A.MotionBlur(blur_limit=5),\n",
    "#             A.MedianBlur(blur_limit=5),\n",
    "#             A.GaussianBlur(blur_limit=5),\n",
    "#             A.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "#         ], p=0.7),\n",
    "\n",
    "#         A.OneOf([\n",
    "#             A.OpticalDistortion(distort_limit=1.0),\n",
    "#             A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "#             A.ElasticTransform(alpha=3),\n",
    "#         ], p=0.7),\n",
    "\n",
    "#         A.CLAHE(clip_limit=4.0, p=0.7),\n",
    "#         A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
    "#         A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
    "#         A.Resize(CFG.img_size, CFG.img_size),\n",
    "#         A.CoarseDropout(max_height=int(CFG.img_size * 0.375), max_width=int(CFG.img_size * 0.375), max_holes=1, min_holes=1, p=0.7),    \n",
    "#         A.Normalize()\n",
    "#     ])\n",
    "\n",
    "#     val_transforms = A.Compose([\n",
    "#         A.Resize(CFG.img_size, CFG.img_size),\n",
    "#         A.Normalize()\n",
    "#     ])\n",
    "\n",
    "#     return train_transforms, val_transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                df: pd.DataFrame,\n",
    "                fp_hdf: str|Path,\n",
    "                transform: A.Compose=None,\n",
    "                ):\n",
    "        self.df = df\n",
    "        if 'target' in self.df.columns:\n",
    "            self.is_training = True\n",
    "            self.targets = df['target'].values\n",
    "        else:\n",
    "            self.is_training = False\n",
    "        self.fp_hdf = h5py.File(fp_hdf, mode=\"r\")\n",
    "        self.isic_ids = df['isic_id'].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        isic_id = self.isic_ids[index]\n",
    "        image = np.array(Image.open(BytesIO(self.fp_hdf[isic_id][()])))\n",
    "        if self.is_training:\n",
    "            target = self.targets[index]\n",
    "        else:\n",
    "            target = []\n",
    "        \n",
    "        if CFG.AUX_LOSS:\n",
    "            pass\n",
    "        return (self._apply_transform(image), target)\n",
    "    \n",
    "    def _apply_transform(self, img:np.ndarray):\n",
    "        \"\"\"apply transform to image\"\"\"\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img)\n",
    "            img = transformed[\"image\"]# .float()# .half()\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Image Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def F_rgb2hsv(rgb: torch.Tensor) -> torch.Tensor:\n",
    "    cmax, cmax_idx = torch.max(rgb, dim=1, keepdim=True)\n",
    "    cmin = torch.min(rgb, dim=1, keepdim=True)[0]\n",
    "    delta = cmax - cmin\n",
    "    hsv_h = torch.empty_like(rgb[:, 0:1, :, :])\n",
    "    cmax_idx[delta == 0] = 3\n",
    "    hsv_h[cmax_idx == 0] = (((rgb[:, 1:2] - rgb[:, 2:3]) / delta) % 6)[cmax_idx == 0]\n",
    "    hsv_h[cmax_idx == 1] = (((rgb[:, 2:3] - rgb[:, 0:1]) / delta) + 2)[cmax_idx == 1]\n",
    "    hsv_h[cmax_idx == 2] = (((rgb[:, 0:1] - rgb[:, 1:2]) / delta) + 4)[cmax_idx == 2]\n",
    "    hsv_h[cmax_idx == 3] = 0.\n",
    "    hsv_h /= 6.\n",
    "    hsv_s = torch.where(cmax == 0, torch.tensor(0.).type_as(rgb), delta / cmax)\n",
    "    hsv_v = cmax\n",
    "    return torch.cat([hsv_h, hsv_s, hsv_v], dim=1)\n",
    "\n",
    "# linear can treat any input size\n",
    "class DynamicLinear(nn.Module):\n",
    "    def __init__(self, out_size):\n",
    "        super(DynamicLinear, self).__init__()\n",
    "        self.out_size = out_size\n",
    "        self.linear = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.linear is None:\n",
    "            in_features = x.size(-1)\n",
    "            self.linear = nn.Linear(in_features, self.out_size).to(x.device)\n",
    "        \n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class timmModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name: str,\n",
    "            pretrained: bool,\n",
    "            in_channels: int,\n",
    "            num_classes: int,\n",
    "            is_training: bool=False\n",
    "        ):\n",
    "        super().__init__()\n",
    "        if 'eva' in CFG.model_name:\n",
    "            self.model = timm.create_model(\n",
    "                model_name=model_name, \n",
    "                pretrained=pretrained, \n",
    "                in_chans=in_channels,\n",
    "                num_classes=num_classes,\n",
    "                # global_pool=''\n",
    "            )\n",
    "        else:\n",
    "            self.model = timm.create_model(\n",
    "                model_name=model_name, \n",
    "                pretrained=pretrained, \n",
    "                in_chans=in_channels,\n",
    "                num_classes=num_classes,\n",
    "                global_pool=''\n",
    "            )\n",
    "        \n",
    "        self.output_type = ['infer', 'loss']\n",
    "        self.is_training = is_training\n",
    "\n",
    "        # model output dim\n",
    "        dim = CFG.output_dim_models[CFG.model_name]\n",
    "        \n",
    "        self.dropout = nn.ModuleList([\n",
    "            nn.Dropout(0.5) for i in range(5)\n",
    "        ])\n",
    "        # self.target=nn.Linear(dim, 1)\n",
    "        self.target=DynamicLinear(out_size=1)\n",
    "        # self.target_aux=nn.Linear(dim, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        batch_size = len(x)\n",
    "        \n",
    "        x = torch.cat([x, F_rgb2hsv(x)],1) # (bs, dim, h, w)\n",
    "        x = self.model(x)    \n",
    "        # print('model output: ', x.shape)\n",
    "        \n",
    "        if not 'eva' in CFG.model_name:\n",
    "            pool = F.adaptive_avg_pool2d(x, 1)\n",
    "            # print('after pooling: ', pool.shape)\n",
    "            reshaped = pool.reshape(batch_size, -1)  \n",
    "            # print('after reshape: ', reshaped.shape)\n",
    "        \n",
    "        else:\n",
    "            reshaped = x\n",
    "        \n",
    "        if self.is_training:\n",
    "            logit = 0\n",
    "            # print(len(self.dropout))\n",
    "            for i in range(len(self.dropout)):\n",
    "                dropped = self.dropout[i](reshaped)\n",
    "                # print(dropped.shape)\n",
    "                logit += self.target(dropped)\n",
    "            logit = logit / len(self.dropout)\n",
    "        else:\n",
    "            logit = self.target(reshaped)\n",
    "            \n",
    "        output = {}\n",
    "        if 'loss' in self.output_type:\n",
    "            if target.dim() == 1:\n",
    "                target = target.view(-1, 1)\n",
    "            output['bce_loss'] = F.binary_cross_entropy_with_logits(logit.float(), target.float())\n",
    "\n",
    "        if 'infer' in self.output_type:\n",
    "            output['target'] = torch.sigmoid(logit.float())\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def initialize_dummy(self):\n",
    "        # Initialize the DynamicLinear layer with dummy input data\n",
    "        original_output_type = self.output_type\n",
    "        self.output_type = ['infer']\n",
    "        \n",
    "        dummy_input = torch.zeros(1, 3, CFG.img_size, CFG.img_size)  # Assuming input size (1, 3, 224, 224)\n",
    "        _ = self.forward(dummy_input)\n",
    "        \n",
    "        self.output_type = original_output_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_meta.columns)\n",
    "display(train_meta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "\n",
    "    if CFG.view:\n",
    "        def show_batch(ds, row=3, col=3, color='rgb'):\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            img_index = np.random.randint(0, len(ds)-1, row*col)\n",
    "            \n",
    "            for i in range(len(img_index)):\n",
    "                img, label = ds[img_index[i]]\n",
    "                img_rgb = img[:3, :, :]\n",
    "                # img_hsv = img[3:6, :, :]\n",
    "                \n",
    "                if color=='rgb':\n",
    "                    img = img_rgb\n",
    "                # elif color=='hsv':\n",
    "                #     img = img_hsv\n",
    "                \n",
    "                if isinstance(img, torch.Tensor):\n",
    "                    img = img.detach().numpy()\n",
    "                    # Check if the image is in (C, H, W) and transpose it to (H, W, C)\n",
    "                    if img.shape[0] == 3:  # Assuming the image is (C, H, W)\n",
    "                        img = np.transpose(img, (1, 2, 0))\n",
    "                \n",
    "                ax = fig.add_subplot(row, col, i + 1, xticks=[], yticks=[])\n",
    "                ax.imshow(img)  # Remove cmap parameter for RGB images\n",
    "                ax.set_title(f'ID: {img_index[i]}; Target: {label}')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        _train_transform, _ = get_transforms()\n",
    "        if CFG.alldata_isic_archive:\n",
    "            _dataset = ISICDataset(df=train_meta, fp_hdf=CFG.TRAIN_HDF5_COMBINED, transform=_train_transform)\n",
    "        else:\n",
    "            _dataset = ISICDataset(df=train_meta, fp_hdf=CFG.TRAIN_HDF5, transform=_train_transform)\n",
    "        show_batch(_dataset)\n",
    "        # show_batch(_dataset, color='hsv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "\n",
    "    # reference\n",
    "    def train_one_fold(val_fold: int, \n",
    "                    train: pd.DataFrame,\n",
    "                    output_path: str|Path\n",
    "                    ):\n",
    "        \"\"\"Main\"\"\"\n",
    "        # If True, forces cuDNN to benchmark multiple convolution algorithms and choose the fastest one\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        set_random_seed(CFG.random_seed, deterministic=CFG.deterministic)\n",
    "        # set device with pytorch env\n",
    "        device = torch.device(CFG.device)\n",
    "        # print(device)\n",
    "        \n",
    "        train_transform, val_transform = get_transforms()\n",
    "        \n",
    "    #     train_dataset = Bird2024Dataset(**train_path_label, transform=train_transform)\n",
    "        if CFG.alldata_isic_archive:\n",
    "            train_dataset = ISICDataset(train[train['fold']!=val_fold], CFG.TRAIN_HDF5_COMBINED, train_transform)\n",
    "            train_dataset_noaugment = ISICDataset(train[train['fold']!=val_fold], CFG.TRAIN_HDF5_COMBINED, val_transform)\n",
    "            val_dataset = ISICDataset(train[train['fold']==val_fold], CFG.TRAIN_HDF5_COMBINED, val_transform)\n",
    "        else:\n",
    "            train_dataset = ISICDataset(train[train['fold']!=val_fold], CFG.TRAIN_HDF5, train_transform)\n",
    "            train_dataset_noaugment = ISICDataset(train[train['fold']!=val_fold], CFG.TRAIN_HDF5, val_transform)\n",
    "            val_dataset = ISICDataset(train[train['fold']==val_fold], CFG.TRAIN_HDF5, val_transform)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=True, drop_last=True)\n",
    "        train_loader_noaugment = torch.utils.data.DataLoader(\n",
    "            train_dataset_noaugment, batch_size=CFG.batch_size, num_workers=4, shuffle=True, drop_last=True)\n",
    "        \n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "        \n",
    "        model = timmModel(\n",
    "            model_name=CFG.model_name, \n",
    "            pretrained=CFG.pretrained, \n",
    "            num_classes=0, # no classification head\n",
    "            in_channels=6, # RBG+HSV\n",
    "            is_training=True\n",
    "        )\n",
    "        # transfer learning\n",
    "        if CFG.PRETRAINED_MODEL:\n",
    "            model.initialize_dummy()\n",
    "            model.load_state_dict(torch.load(CFG.PRETRAINED_MODEL, map_location=device))\n",
    "            \n",
    "        model = model.to(device)\n",
    "\n",
    "        \n",
    "        optimizer = optim.AdamW(params=model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "        scheduler = lr_scheduler.OneCycleLR(\n",
    "            optimizer=optimizer, epochs=CFG.max_epoch,\n",
    "            pct_start=0.0, steps_per_epoch=len(train_loader),\n",
    "            max_lr=CFG.lr, div_factor=25, final_div_factor=1e4\n",
    "        )\n",
    "        \n",
    "    #     loss_func = KLDivLossWithLogits()\n",
    "        # loss_func = nn.CrossEntropyLoss()\n",
    "        # loss_func = nn.BCEWithLogitsLoss()\n",
    "    #     loss_func = FocalLossBCE()\n",
    "        # loss_func.to(device)\n",
    "    #     loss_func_val = KLDivLossWithLogitsForVal()\n",
    "    #     loss_func_val = nn.CrossEntropyLoss()\n",
    "        # loss_func_val = nn.BCEWithLogitsLoss()\n",
    "    #     loss_func_val = FocalLossBCE()\n",
    "        \n",
    "        use_amp = CFG.enable_amp\n",
    "        scaler = amp.GradScaler('cuda', enabled=use_amp)\n",
    "        # scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "        \n",
    "        best_val_loss = 1.0e+09\n",
    "        best_epoch = 0\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        cumulative_elapsed_time = 0\n",
    "        \n",
    "        for epoch in range(1, CFG.max_epoch + 1):\n",
    "            if CFG.change_dataset & epoch >= ((CFG.max_epoch+1) * 0.6):\n",
    "                train_loader = train_loader_noaugment\n",
    "            epoch_start = time()\n",
    "            model.train()\n",
    "            for batch in tqdm(train_loader):\n",
    "                \n",
    "                x, t = batch\n",
    "                if CFG.standardization:\n",
    "                    x = (x - x.min()) / (x.max() - x.min() +1e-6) * 255\n",
    "                else:\n",
    "                    x = x.float()/255\n",
    "                # t = t.float()\n",
    "    #             print(x)\n",
    "    #             print(t)\n",
    "                x = to_device(x, device)\n",
    "                t = to_device(t, device)\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "                # with torch.cuda.amp.autocast(use_amp):\n",
    "                with amp.autocast('cuda', enabled=use_amp):\n",
    "                    output = model(x, t)\n",
    "                    loss = output['bce_loss']\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                train_loss += loss.item()\n",
    "                scheduler.step()\n",
    "                \n",
    "            train_loss /= len(train_loader)\n",
    "                \n",
    "            model.eval()\n",
    "            for batch in tqdm(val_loader):\n",
    "                x, t = batch\n",
    "                if CFG.standardization:\n",
    "                    x = (x - x.min()) / (x.max() - x.min() +1e-6) * 255\n",
    "                else:\n",
    "                    x = x.float()/255\n",
    "                x = to_device(x, device)\n",
    "                t = to_device(t, device)\n",
    "                # with torch.no_grad(), torch.cuda.amp.autocast(use_amp):\n",
    "                with torch.no_grad(), amp.autocast('cuda', enabled=use_amp):\n",
    "                    output = model(x, t)\n",
    "                loss = output['bce_loss']\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_epoch = epoch\n",
    "                best_val_loss = val_loss\n",
    "                # print(\"save model\")\n",
    "                torch.save(model.state_dict(), str(output_path / f'snapshot_epoch_{epoch}.pth'))\n",
    "            \n",
    "            elapsed_time = time() - epoch_start\n",
    "            cumulative_elapsed_time += elapsed_time\n",
    "            with open(str(output_path / f'train_log.txt'), 'a') as f:\n",
    "                f.write('\\n')\n",
    "                f.write(f'exp: {CFG.exp}, [epoch {epoch}] train loss: {train_loss: .6f}, val loss: {val_loss: .6f}, elapsed_time: {elapsed_time: .3f}')\n",
    "            \n",
    "            # log\n",
    "            if CFG.enable_wandb:\n",
    "                wandb.log({\"Train Loss\": train_loss, \n",
    "                        \"Val Loss\": val_loss, \n",
    "                        \"Cumulative Time(m)\": cumulative_elapsed_time/60,\n",
    "                        \"Fold\": val_fold}\n",
    "                        )\n",
    "            print(\n",
    "                f\"[epoch {epoch}] train loss: {train_loss: .6f}, val loss: {val_loss: .6f}, cumulative_elapsed_time: {cumulative_elapsed_time/60: .1f}m , elapsed_time: {elapsed_time/60: .3f}m\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            if epoch - best_epoch > CFG.es_patience:\n",
    "                with open(str(output_path / f'train_log.txt'), 'a') as f:\n",
    "                    f.write('\\n')\n",
    "                    f.write(\"Early Stopping!\")\n",
    "                print(\"Early Stopping!\")\n",
    "                break\n",
    "                \n",
    "            train_loss = 0\n",
    "            val_loss = 0\n",
    "                \n",
    "        return val_fold, best_epoch, best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete previous exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "\n",
    "    # select the best model and delete others\n",
    "    best_log_list = []\n",
    "    for (fold_id) in range(CFG.n_folds):\n",
    "        \n",
    "        # select the best model\n",
    "        exp_dir_path = CFG.OUTPUT_DIR / f\"fold{fold_id}\"        \n",
    "        for p in exp_dir_path.glob(\"*.pth\"):\n",
    "            # delete\n",
    "            p.unlink()\n",
    "        for p in exp_dir_path.glob(\"*.txt\"):\n",
    "            # delete\n",
    "            p.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    score_list = []\n",
    "    print('='*20)\n",
    "    print('experiment: ', CFG.exp)\n",
    "    print('='*20)\n",
    "    for fold_id in range(CFG.n_folds):\n",
    "        output_path = CFG.OUTPUT_DIR / f\"fold{fold_id}\"\n",
    "        output_path.mkdir(exist_ok=True, parents=True)\n",
    "        print(f\"[fold{fold_id}]\")\n",
    "        score_list.append(train_one_fold(fold_id, train_meta, output_path))\n",
    "        \n",
    "    with open(CFG.OUTPUT_LOG, 'a') as f:\n",
    "        f.write('\\n')\n",
    "        f.write(f'exp: {CFG.exp}')\n",
    "        f.write('\\n')\n",
    "        f.write(str(score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    print(score_list)\n",
    "    score_list_log = score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "\n",
    "    # select the best model and delete others\n",
    "    best_log_list = []\n",
    "    for (fold_id, best_epoch, _) in score_list:\n",
    "        \n",
    "        # select the best model\n",
    "        exp_dir_path = CFG.OUTPUT_DIR / f\"fold{fold_id}\"\n",
    "        best_model_path = exp_dir_path / f\"snapshot_epoch_{best_epoch}.pth\"\n",
    "        # copy to new place\n",
    "        copy_to = CFG.OUTPUT_DIR / f\"./best_model_fold{fold_id}.pth\"\n",
    "        shutil.copy(best_model_path, copy_to)\n",
    "        \n",
    "        for p in exp_dir_path.glob(\"*.pth\"):\n",
    "            # delete\n",
    "            p.unlink()\n",
    "        # for p in exp_dir_path.glob(\"*.txt\"):\n",
    "        #     # delete\n",
    "        #     p.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for inference\n",
    "def run_inference_loop(model, loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    model.output_type = ['infer']\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            x = to_device(batch[0], device)\n",
    "            if CFG.standardization:\n",
    "                x = (x - x.min()) / (x.max() - x.min() +1e-6) * 255\n",
    "            else:\n",
    "                x = x.float()/255\n",
    "            output = model(x)\n",
    "            y = output['target']\n",
    "            pred_list.append(y.detach().cpu().numpy())\n",
    "    \n",
    "    # concatenate to vertical (to df like from long scroll like)\n",
    "    pred_arr = np.concatenate(pred_list)\n",
    "    del pred_list\n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "\n",
    "    # predict for train data with metrix(CV. not test data)\n",
    "\n",
    "\n",
    "    # duplicate check\n",
    "    column_to_check = 'isic_id'\n",
    "    # Drop duplicate rows based on the specified column\n",
    "    train_meta = train_meta.drop_duplicates(subset=[column_to_check], keep='first').reset_index(drop=True)\n",
    "\n",
    "    # label_arr = train[CLASSES].values\n",
    "    oof_pred_arr = np.zeros((len(train_meta), CFG.n_classes-1))\n",
    "    if CFG.TTA:\n",
    "        oof_pred_arr_TTA = np.zeros((len(train_meta), CFG.n_classes-1))\n",
    "    score_list = []\n",
    "\n",
    "    for fold_id in range(CFG.n_folds):\n",
    "        print(f\"\\n[fold {fold_id}]\")\n",
    "        device = torch.device(CFG.device)\n",
    "\n",
    "        # get_dataloader\n",
    "        val_transform_TTA, val_transform = get_transforms()\n",
    "        if CFG.alldata_isic_archive:\n",
    "            val_dataset = ISICDataset(df=train_meta[train_meta[\"fold\"] == fold_id], fp_hdf=CFG.TRAIN_HDF5_COMBINED, transform=val_transform)\n",
    "            val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "            if CFG.TTA:\n",
    "                val_dataset_TTA = ISICDataset(df=train_meta[train_meta[\"fold\"] == fold_id], fp_hdf=CFG.TRAIN_HDF5_COMBINED, transform=val_transform_TTA)\n",
    "                val_loader_TTA = torch.utils.data.DataLoader(val_dataset_TTA, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "        else:\n",
    "            val_dataset = ISICDataset(df=train_meta[train_meta[\"fold\"] == fold_id], fp_hdf=CFG.TRAIN_HDF5, transform=val_transform)\n",
    "            val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "            if CFG.TTA:\n",
    "                val_dataset_TTA = ISICDataset(df=train_meta[train_meta[\"fold\"] == fold_id], fp_hdf=CFG.TRAIN_HDF5, transform=val_transform_TTA)\n",
    "                val_loader_TTA = torch.utils.data.DataLoader(val_dataset_TTA, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "\n",
    "        # # get model\n",
    "        model_path = CFG.OUTPUT_DIR / f\"best_model_fold{fold_id}.pth\"\n",
    "        model = timmModel(\n",
    "            model_name=CFG.model_name, \n",
    "            pretrained=False, \n",
    "            in_channels=6,\n",
    "            num_classes=0,\n",
    "            is_training=False\n",
    "        )\n",
    "        model.initialize_dummy()  # Initialize with dummy data for dynamic linear\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "        # # inference\n",
    "        val_pred = run_inference_loop(model, val_loader, device)\n",
    "        val_idx = train_meta[train_meta[\"fold\"] == fold_id].index.values\n",
    "        oof_pred_arr[val_idx] = val_pred\n",
    "        if CFG.TTA:\n",
    "            val_pred_TTA = run_inference_loop(model, val_loader_TTA, device)\n",
    "            val_idx_TTA = train_meta[train_meta[\"fold\"] == fold_id].index.values\n",
    "            oof_pred_arr_TTA[val_idx_TTA] = val_pred_TTA\n",
    "\n",
    "        del val_idx\n",
    "        del model, val_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "    if CFG.TTA:\n",
    "        # ref. CFG.TTA_rate = {'None':value, 'with_train_aug':value}\n",
    "        oof_pred_arr_merged = (oof_pred_arr * CFG.TTA_rate['None']) + (oof_pred_arr_TTA * CFG.TTA_rate['with_train_aug'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test of averaged model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of averaged model\n",
    "if CFG.test_of_averaged_model:\n",
    "    # predict for train data with metrix(CV. not test data)\n",
    "\n",
    "\n",
    "    # duplicate check\n",
    "    column_to_check = 'isic_id'\n",
    "    # Drop duplicate rows based on the specified column\n",
    "    train_meta = train_meta.drop_duplicates(subset=[column_to_check], keep='first').reset_index(drop=True)\n",
    "\n",
    "    # label_arr = train[CLASSES].values\n",
    "    oof_pred_arr = np.zeros((len(train_meta), CFG.n_classes-1))\n",
    "    score_list = []\n",
    "\n",
    "    for fold_id in range(1):\n",
    "        print(f\"\\n[fold {fold_id}]\")\n",
    "        device = torch.device(CFG.device)\n",
    "\n",
    "        # get_dataloader\n",
    "        _, val_transform = get_transforms()\n",
    "        val_dataset = ISICDataset(df=train_meta, fp_hdf=CFG.TRAIN_HDF5_COMBINED, transform=val_transform)\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "\n",
    "        # # get model\n",
    "        model_path = CFG.OUTPUT_DIR / f\"averaged_model.pth\"\n",
    "        model = timmModel(\n",
    "            model_name=CFG.model_name, \n",
    "            pretrained=False, \n",
    "            in_channels=6,\n",
    "            num_classes=0,\n",
    "            is_training=False\n",
    "        )\n",
    "        model.initialize_dummy()  # Initialize with dummy data for dynamic linear\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "        # # inference\n",
    "        val_pred = run_inference_loop(model, val_loader, device)\n",
    "        # val_idx = train_meta[train_meta[\"fold\"] == fold_id].index.values\n",
    "        oof_pred_arr = val_pred\n",
    "\n",
    "        del val_idx\n",
    "        del model, val_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80):\n",
    "    v_gt = abs(np.asarray(solution.values)-1)\n",
    "    v_pred = np.array([1.0 - x for x in submission.values])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    # make true array\n",
    "    label_arr = train_meta['target']\n",
    "    # one-hot\n",
    "    # ture_arr = np.zeros((label_arr.size, CFG.n_classes))\n",
    "    # ture_arr[np.arange(label_arr.size), label_arr] = 1\n",
    "    ture_arr = pd.DataFrame(label_arr)\n",
    "\n",
    "    # oof\n",
    "    oof = pd.DataFrame(oof_pred_arr)\n",
    "    if CFG.TTA:\n",
    "        oof = pd.DataFrame(oof_pred_arr_merged)\n",
    "\n",
    "    micro_roc_auc_ovr = comp_score(\n",
    "        ture_arr,\n",
    "        oof,\n",
    "        \"\"\n",
    "    )\n",
    "\n",
    "    print(f\"CV: Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.10f}\")\n",
    "    if CFG.enable_wandb:\n",
    "        wandb.log({\"CV\": micro_roc_auc_ovr})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    with open(CFG.OUTPUT_LOG, 'a') as f:\n",
    "        f.write('\\n')\n",
    "        f.write(f'exp: {CFG.exp}')\n",
    "        f.write('\\n')\n",
    "        f.write(f\"CV: Micro-averaged One-vs-Rest ROC AUC score: {micro_roc_auc_ovr:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    display(oof.head())\n",
    "    display(ture_arr.head())\n",
    "    display(oof.tail())\n",
    "    display(ture_arr.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for test data with metrix\n",
    "if (CFG.is_kaggle & CFG.is_infer) or CFG.use_tabler:\n",
    "\n",
    "    pred_arr = []\n",
    "    pred_arr_TTA = []\n",
    "\n",
    "    for fold_id in range(CFG.n_folds):\n",
    "        print(f\"\\n[fold {fold_id}]\")\n",
    "        device = torch.device(CFG.device)\n",
    "\n",
    "        # get_dataloader\n",
    "        val_transform_TTA, val_transform = get_transforms()\n",
    "        val_dataset = ISICDataset(df=test_meta, fp_hdf=CFG.TEST_HDF5, transform=val_transform)\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=CFG.batch_size, num_workers=2, shuffle=False, drop_last=False)\n",
    "        if CFG.TTA:\n",
    "            val_dataset_TTA = ISICDataset(df=test_meta, fp_hdf=CFG.TEST_HDF5, transform=val_transform_TTA)\n",
    "            val_loader_TTA = torch.utils.data.DataLoader(\n",
    "                val_dataset_TTA, batch_size=CFG.batch_size, num_workers=2, shuffle=False, drop_last=False)\n",
    "\n",
    "        # get model\n",
    "        model_path = CFG.OUTPUT_DIR / f\"best_model_fold{fold_id}.pth\"\n",
    "        model = timmModel(\n",
    "            model_name=CFG.model_name, \n",
    "            pretrained=False, \n",
    "            in_channels=6,\n",
    "            num_classes=0,\n",
    "            is_training=False\n",
    "        )\n",
    "        model.initialize_dummy()\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "        # # inference\n",
    "        val_pred = run_inference_loop(model, val_loader, device)\n",
    "        pred_arr.append(val_pred)\n",
    "        if CFG.TTA:\n",
    "            val_pred_TTA = run_inference_loop(model, val_loader_TTA, device)\n",
    "            pred_arr_TTA.append(val_pred_TTA)\n",
    "\n",
    "        del model, val_loader, val_pred\n",
    "        if CFG.TTA:\n",
    "            del val_loader_TTA, val_pred_TTA\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    # averaging\n",
    "    print(len(pred_arr))\n",
    "    if len(pred_arr) >= 2:    \n",
    "        pred_arr = np.mean(pred_arr, axis=0)\n",
    "    print(pred_arr.shape)\n",
    "    \n",
    "    if CFG.TTA:\n",
    "        print(len(pred_arr_TTA))\n",
    "        if len(pred_arr_TTA) >= 2:    \n",
    "            pred_arr_TTA = np.mean(pred_arr_TTA, axis=0)\n",
    "        print(pred_arr_TTA.shape)\n",
    "\n",
    "        pred_arr = (pred_arr * CFG.TTA_rate['None']) + (pred_arr_TTA * CFG.TTA_rate['with_train_aug'])\n",
    "\n",
    "\n",
    "    pred_df = pd.DataFrame(pred_arr, columns=['target'])\n",
    "    display(pred_df)\n",
    "\n",
    "    # submission\n",
    "    df_sub = pd.read_csv(CFG.SAMPLE_SUB)\n",
    "    df_sub[\"target\"] = pred_df\n",
    "    display(df_sub.head())\n",
    "    df_sub.to_csv('submission.csv', index=False)\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Tabler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.use_tabler:\n",
    "    image_pred_col = 'image_prediction'\n",
    "    \n",
    "    if not CFG.is_infer:\n",
    "        # add image model prediction to train_meta as a feature\n",
    "        \n",
    "        oof = pd.DataFrame(oof_pred_arr, columns=[image_pred_col])\n",
    "        display(oof.head())\n",
    "        assert len(oof) == len(train_meta)\n",
    "        train_meta[image_pred_col] = oof[image_pred_col].values\n",
    "        # train_meta = train_meta.merge(oof[image_pred_col], \n",
    "        #                       on='isic_id', \n",
    "        #                       how='left')\n",
    "        \n",
    "    # add using feature\n",
    "    if CFG.image_pred_as_tabler_feature:\n",
    "        feature_cols.append(image_pred_col)\n",
    "\n",
    "    # add image model prediction to test_meta as a feature\n",
    "    assert len(pred_df) == len(test_meta)\n",
    "    display(pred_df)\n",
    "    test_meta[image_pred_col] = pred_df['target'].values\n",
    "    # test_meta = test_meta.merge(pred_df[image_pred_col], \n",
    "    #                       on='isic_id', \n",
    "    #                       how='left')\n",
    "    # already added  \n",
    "    # feature_cols.append(image_pred_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Optuna HyperParam Tuned Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10.1.1 LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.use_tabler and ((not CFG.is_infer) or (not CFG.image_pred_as_tabler_feature)):\n",
    "    lgb_params = {\n",
    "        'objective':        'binary',\n",
    "        'verbosity':        -1,\n",
    "        'n_iter':           200,\n",
    "        'boosting_type':    'gbdt',\n",
    "        'random_state':     seed,\n",
    "        'lambda_l1':        0.08758718919397321, \n",
    "        'lambda_l2':        0.0039689175176025465, \n",
    "        'learning_rate':    0.03231007103195577, \n",
    "        'max_depth':        4, \n",
    "        'num_leaves':       103, \n",
    "        'colsample_bytree': 0.8329551585827726, \n",
    "        'colsample_bynode': 0.4025961355653304, \n",
    "        'bagging_fraction': 0.7738954452473223, \n",
    "        'bagging_freq':     4, \n",
    "        'min_data_in_leaf': 85, \n",
    "        'scale_pos_weight': 2.7984184778875543,\n",
    "    }\n",
    "\n",
    "    lgb_model = Pipeline([\n",
    "        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10.1.2 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.use_tabler and ((not CFG.is_infer) or (not CFG.image_pred_as_tabler_feature)):\n",
    "    cb_params = {\n",
    "        'loss_function':     'Logloss',\n",
    "        'iterations':        200,\n",
    "        'verbose':           False,\n",
    "        'random_state':      seed,\n",
    "        'max_depth':         7, \n",
    "        'learning_rate':     0.06936242010150652, \n",
    "        'scale_pos_weight':  2.6149345838209532, \n",
    "        'l2_leaf_reg':       6.216113851699493, \n",
    "        'subsample':         0.6249261779711819, \n",
    "        'min_data_in_leaf':  24,\n",
    "        'cat_features':      cat_cols,\n",
    "    }\n",
    "\n",
    "    cb_model = Pipeline([\n",
    "        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n",
    "        ('classifier', cb.CatBoostClassifier(**cb_params)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10.1.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.use_tabler and ((not CFG.is_infer) or (not CFG.image_pred_as_tabler_feature)):\n",
    "    xgb_params = {\n",
    "        'enable_categorical': True,\n",
    "        'tree_method':        'hist',\n",
    "        'random_state':       seed,\n",
    "        'learning_rate':      0.08501257473292347, \n",
    "        'lambda':             8.879624125465703, \n",
    "        'alpha':              0.6779926606782505, \n",
    "        'max_depth':          6, \n",
    "        'subsample':          0.6012681388711075, \n",
    "        'colsample_bytree':   0.8437772277074493, \n",
    "        'colsample_bylevel':  0.5476090898823716, \n",
    "        'colsample_bynode':   0.9928601203635129, \n",
    "        'scale_pos_weight':   3.29440313334688,\n",
    "    }\n",
    "\n",
    "    xgb_model = Pipeline([\n",
    "        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n",
    "        ('classifier', xgb.XGBClassifier(**xgb_params)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.use_tabler and ((not CFG.is_infer) or (not CFG.image_pred_as_tabler_feature)):\n",
    "    estimator = VotingClassifier([\n",
    "        ('lgb', lgb_model), ('cb', cb_model), ('xgb', xgb_model),\n",
    "    ], voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.use_tabler and ((not CFG.is_infer)):\n",
    "    # Assuming df_train already has a 'fold' column with values 0-4\n",
    "    X = train_meta[feature_cols]\n",
    "    y = train_meta[target_col]\n",
    "\n",
    "    # Create a PredefinedSplit object using the 'fold' column\n",
    "    fold_indices = train_meta['fold'].values\n",
    "    cv = PredefinedSplit(fold_indices)\n",
    "\n",
    "    # if CFG.is_infer: # inference\n",
    "    #     with open(str(CFG.OUTPUT_DIR / f'voting_classifier.pkl'), 'rb') as file:\n",
    "    #         estimator = pickle.load(file)\n",
    "    # Perform cross-validation\n",
    "    val_score = cross_val_score(\n",
    "        estimator=estimator, \n",
    "        X=X, y=y, \n",
    "        cv=cv,\n",
    "        scoring=custom_metric,\n",
    "    )\n",
    "\n",
    "    print(np.mean(val_score), val_score)\n",
    "    if CFG.enable_wandb:\n",
    "        wandb.log({\"tabler_CV\": np.mean(val_score)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.use_tabler and ((not CFG.is_infer) or (not CFG.image_pred_as_tabler_feature)):\n",
    "    X, y = train_meta[feature_cols], train_meta[target_col]\n",
    "\n",
    "    estimator.fit(X, y)\n",
    "    # save\n",
    "    if not CFG.is_kaggle:\n",
    "        with open(str(CFG.OUTPUT_DIR / f'voting_classifier.pkl'), 'wb') as file:\n",
    "            pickle.dump(estimator, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.use_tabler:\n",
    "    \n",
    "    if CFG.is_infer: # inference\n",
    "        with open(str(CFG.OUTPUT_DIR / f'voting_classifier.pkl'), 'rb') as file:\n",
    "            estimator = pickle.load(file)\n",
    "        df_subm['target'] = estimator.predict_proba(test_meta[feature_cols])[:, 1]\n",
    "        df_subm.to_csv('submission.csv')\n",
    "    else: # training\n",
    "        df_subm['target'] = estimator.predict_proba(test_meta[feature_cols])[:, 1]\n",
    "        \n",
    "    if CFG.ensemble_image_table:\n",
    "        # image prediction\n",
    "        print('image pred')\n",
    "        display(pred_df)\n",
    "        # table prediction\n",
    "        print('table pred')\n",
    "        display(df_subm)\n",
    "        # blending\n",
    "        df_subm['target'] = (df_subm['target'].values * 0.5) + (pred_df['target'].values * 0.5)\n",
    "        df_subm.to_csv('submission.csv')\n",
    "        \n",
    "        \n",
    "        print('blended pred')\n",
    "        display(df_subm.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.ensemble_image_table:\n",
    "\n",
    "    # make true array\n",
    "    label_arr = train_meta['target']\n",
    "    # one-hot\n",
    "    # ture_arr = np.zeros((label_arr.size, CFG.n_classes))\n",
    "    # ture_arr[np.arange(label_arr.size), label_arr] = 1\n",
    "    ture_arr = pd.DataFrame(label_arr)\n",
    "\n",
    "    # pred\n",
    "    pred = estimator.predict_proba(train_meta[feature_cols])[:, 1]\n",
    "    pred = pd.DataFrame(pred)\n",
    "\n",
    "    micro_roc_auc_ovr = comp_score(\n",
    "        ture_arr,\n",
    "        pred,\n",
    "        \"\"\n",
    "    )\n",
    "\n",
    "    print(f\"CV: Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.10f}\")\n",
    "    if CFG.enable_wandb:\n",
    "        wandb.log({\"CV\": micro_roc_auc_ovr})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in estimator.estimators_:\n",
    "    model = model['classifier']\n",
    "    model_name = str(model)\n",
    "    model_name_list = ['LGBM', 'catboost', 'XGB']\n",
    "    number_of_show = 10\n",
    "    if model_name_list[0] in model_name:\n",
    "        lgb.plot_importance(model, max_num_features=number_of_show, importance_type='split')\n",
    "        plt.title('LGBM Feature Importance - Number of Splits')\n",
    "        plt.show()\n",
    "        lgb.plot_importance(model, max_num_features=number_of_show, importance_type='gain')\n",
    "        plt.title('LGBM Feature Importance - Gain')\n",
    "        plt.show()\n",
    "    if model_name_list[1] in model_name:\n",
    "        # PVC\n",
    "        pve_importances = model.get_feature_importance(type='PredictionValuesChange') # default type\n",
    "        sorted_indices = np.argsort(pve_importances)[-number_of_show:]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(np.array(feature_cols)[sorted_indices], pve_importances[sorted_indices])\n",
    "        plt.xlabel('Importance')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.title('CatBoost Sorted Prediction Values Change (PVE) Feature Importance')\n",
    "        plt.show()\n",
    "        # # Shapley\n",
    "        # shap_values = model.get_feature_importance(cb.Pool(X,y), type='ShapValues')\n",
    "        # shap_importances = np.mean(np.abs(shap_values[:, :-1]), axis=0)\n",
    "        # sorted_indices = np.argsort(shap_importances)[-number_of_show:]\n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        # plt.barh(np.array(feature_cols)[sorted_indices], shap_importances[sorted_indices])\n",
    "        # plt.xlabel('Importance')\n",
    "        # plt.ylabel('Feature')\n",
    "        # plt.title('CatBoost Sorted Shapley Values Feature Importance')\n",
    "        # plt.show()\n",
    "    if model_name_list[2] in model_name:\n",
    "        xgb.plot_importance(model, importance_type='weight', title='XGB Feature Importance by Weight', xlabel='Importance', ylabel='Feature', max_num_features=number_of_show)\n",
    "        plt.show()\n",
    "\n",
    "        xgb.plot_importance(model, importance_type='gain', title='XGB Feature Importance by Gain', xlabel='Importance', ylabel='Feature', max_num_features=number_of_show)\n",
    "        plt.show()\n",
    "\n",
    "        xgb.plot_importance(model, importance_type='cover', title='XGB Feature Importance by Cover', xlabel='Importance', ylabel='Feature', max_num_features=number_of_show)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dfs\n",
    "if (not CFG.is_infer) and (not CFG.is_kaggle):\n",
    "    train_meta.to_parquet(CFG.OUTPUT_DIR / 'train_meta.parquet', index=False)\n",
    "    test_meta.to_parquet(CFG.OUTPUT_DIR / 'test_meta.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
