{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import typing as tp\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import timm\n",
    "from time import time\n",
    "from tqdm.notebook import tqdm\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.cuda import amp\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \n",
    "    exp = 23\n",
    "    \n",
    "    is_kaggle = False\n",
    "    is_infer = False\n",
    "    if is_kaggle:\n",
    "        OUTPUT_DIR = Path('/kaggle/input/isic2024-baseline')\n",
    "        TRAIN_DIR = Path('/kaggle/input/isic-2024-challenge/train-image/image')\n",
    "        TRAIN_HDF5 = Path('/kaggle/input/isic-2024-challenge/train-image.hdf5')\n",
    "        TEST_HDF5 = Path('/kaggle/input/isic-2024-challenge/test-image.hdf5')\n",
    "        TRAIN_META = Path('/kaggle/input/isic-2024-challenge/train-metadata.csv')\n",
    "        TEST_META = Path('/kaggle/input/isic-2024-challenge/test-metadata.csv')\n",
    "        SAMPLE_SUB = Path('/kaggle/input/isic-2024-challenge/sample_submission.csv')\n",
    "        PRETRAINED_MODEL = ''\n",
    "        \n",
    "    else:\n",
    "        OUTPUT_DIR = Path(f'/root/Development/Kaggle/ISIC2024/main/models/experiments/exp{exp}/outputs')\n",
    "        OUTPUT_LOG = Path(f'/root/Development/Kaggle/ISIC2024/main/models/experiments/exp{exp}/log.txt')\n",
    "        TRAIN_DIR = Path('/root/Development/Kaggle/ISIC2024/data/raw/train-image/image')\n",
    "        TRAIN_HDF5 = Path('/root/Development/Kaggle/ISIC2024/data/raw/train-image.hdf5')\n",
    "        TEST_HDF5 = Path('/root/Development/Kaggle/ISIC2024/data/raw/test-image.hdf5')\n",
    "        TRAIN_META = Path('/root/Development/Kaggle/ISIC2024/data/raw/train-metadata.csv')\n",
    "        TEST_META = Path('/root/Development/Kaggle/ISIC2024/data/raw/test-metadata.csv')\n",
    "        SAMPLE_SUB = Path('/root/Development/Kaggle/ISIC2024/data/raw/sample_submission.csv')\n",
    "        TRAIN_META_ADD = Path('/root/Development/Kaggle/ISIC2024/data/external/All/metadata.csv')\n",
    "        TRAIN_HDF5_ADD = Path('/root/Development/Kaggle/ISIC2024/data/external/All/image.hdf5')\n",
    "        TRAIN_HDF5_COMBINED = Path('/root/Development/Kaggle/ISIC2024/data/processed/train-image-combined.hdf5')\n",
    "        PRETRAINED_MODEL = ''\n",
    "        # PRETRAINED_MODEL = Path('/root/Development/Kaggle/ISIC2024/main/models/experiments/exp10/outputs/averaged_model.pth')\n",
    "        \n",
    "    \n",
    "        \n",
    "    max_epoch = 9\n",
    "    n_folds = 5\n",
    "    n_classes = 2\n",
    "    random_seed = 42\n",
    "    deterministic = True\n",
    "    enable_amp = True\n",
    "    view = True\n",
    "    change_dataset = True\n",
    "    standardization = True\n",
    "    oversampling = False\n",
    "    oversampling_percent = 3\n",
    "        \n",
    "    model_name = 'eva02_small_patch14_224.mim_in22k'\n",
    "    output_dim_models = {\n",
    "        \"resnet18.a1_in1k\": 512,\n",
    "        \"efficientnet_b0.ra_in1k\": 320,\n",
    "        \"tf_efficientnet_b0.ns_jft_in1k\": 1280,\n",
    "        # 'tf_efficientnet_b5.ns_jft_in1k': 1280,\n",
    "        'tf_efficientnet_b3.ns_jft_in1k': 1536,\n",
    "        'eva02_small_patch14_224.mim_in22k': 384,\n",
    "    }\n",
    "    pretrained = True\n",
    "    img_size = 224\n",
    "    # img_size = 384\n",
    "    interpolation = cv2.INTER_LINEAR\n",
    "\n",
    "    es_patience = 5 \n",
    "    batch_size = 128\n",
    "    \n",
    "    lr = 1.0e-03\n",
    "    # lr = 1.0e-04\n",
    "    weight_decay = 1.0e-02 # default\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_meta = pd.read_csv(CFG.TRAIN_META)\n",
    "test_meta = pd.read_csv(CFG.TEST_META)\n",
    "print(len(train_meta))\n",
    "print(len(test_meta))\n",
    "\n",
    "# head\n",
    "display(train_meta[train_meta['target'] > 0.5].head(10))\n",
    "display(train_meta.head())\n",
    "display(test_meta.head())\n",
    "\n",
    "\n",
    "if not CFG.is_infer:\n",
    "    train_meta_add = pd.read_csv(CFG.TRAIN_META_ADD)\n",
    "    print(len(train_meta_add))\n",
    "    display(train_meta_add.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    # only benign or maligant\n",
    "    train_meta_add = train_meta_add[train_meta_add['benign_malignant'].isin(['benign', 'malignant'])]\n",
    "    # make the target column\n",
    "    train_meta_add['target'] = train_meta_add['benign_malignant'].apply(lambda x: 1 if x == 'malignant' else 0)\n",
    "    # assign difference patientid\n",
    "    train_meta_add['patient_id'] = [\n",
    "        f\"example_{i+1}\" if pd.isna(id) else id\n",
    "        for i, id in enumerate(train_meta_add['patient_id'])\n",
    "    ]\n",
    "\n",
    "    train_meta_add['additional'] = 1\n",
    "\n",
    "    display(train_meta_add.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    # delete clothes and others\n",
    "    # List of IDs to drop\n",
    "    ids_to_drop = ['ISIC_0573025', 'ISIC_1443812', 'ISIC_5374420', 'ISIC_2611119', 'ISIC_2691718', 'ISIC_9689783', 'ISIC_9520696', 'ISIC_8651165', 'ISIC_9385142', 'ISIC_9680590']\n",
    "    train_meta = train_meta.drop(train_meta[train_meta['isic_id'].isin(ids_to_drop)].index)\n",
    "\n",
    "    # only has lesion_id(strgong label)\n",
    "    train_meta = train_meta[train_meta['lesion_id'].notnull()].reset_index(drop=True)\n",
    "    # add \"additional\" column\n",
    "    train_meta['additional'] = 0\n",
    "\n",
    "    print(len(train_meta))\n",
    "    print(len(train_meta[train_meta['target']==1]))\n",
    "    print(len(train_meta[train_meta['target']==1]) / len(train_meta) * 100, '%')\n",
    "    display(train_meta.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat both data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    concatenated = pd.concat([train_meta, train_meta_add], axis=0)\n",
    "    # train_meta = concatenated.reset_index()\n",
    "    # display(train_meta.head())\n",
    "    # display(train_meta.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split to fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "\n",
    "    def split_fold(df:pd.DataFrame):\n",
    "        # if 'fold' in df.columns:\n",
    "        #     return df\n",
    "        \n",
    "        df['fold'] = -1\n",
    "        # object\n",
    "        skf = StratifiedGroupKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.random_seed)\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df, df['target'], df['patient_id'])):\n",
    "            df.loc[test_index, 'fold'] = i\n",
    "        \n",
    "        return df\n",
    "            \n",
    "    train_meta = split_fold(train_meta)\n",
    "    display(train_meta.head().T)\n",
    "\n",
    "    # check\n",
    "    if CFG.view:\n",
    "        print(train_meta.groupby('fold')['target'].value_counts().head(300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "    if CFG.oversampling:\n",
    "\n",
    "        percent = CFG.oversampling_percent\n",
    "\n",
    "        train_meta_mali = train_meta[train_meta['target']==1]\n",
    "        for _ in range(100):\n",
    "            train_meta = pd.concat([train_meta, train_meta_mali], axis=0)\n",
    "            if len(train_meta[train_meta['target']==1]) / len(train_meta) * 100 >= percent:\n",
    "                print(f'over {percent}% malignant')\n",
    "                break\n",
    "\n",
    "        print(len(train_meta))\n",
    "        print(len(train_meta[train_meta['target']==1]))\n",
    "        print(len(train_meta[train_meta['target']==1]) / len(train_meta) * 100, '%')\n",
    "\n",
    "        del percent\n",
    "\n",
    "        if CFG.view:\n",
    "            print(train_meta.groupby('fold')['target'].value_counts().head(300))\n",
    "            display(train_meta.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed in each env\n",
    "def set_random_seed(seed: int = 42, deterministic: bool = False):\n",
    "    \"\"\"Set seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n",
    "\n",
    "# function to set tensor to device\n",
    "def to_device(\n",
    "    tensors: tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]],\n",
    "    device: torch.device, *args, **kwargs\n",
    "):\n",
    "    if isinstance(tensors, tuple):\n",
    "        return (t.to(device, *args, **kwargs) for t in tensors)\n",
    "    elif isinstance(tensors, dict):\n",
    "        return {\n",
    "            k: t.to(device, *args, **kwargs) for k, t in tensors.items()}\n",
    "    else:\n",
    "        return tensors.to(device, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_transforms(include_light=False):\n",
    "    augmentations_train = A.Compose([\n",
    "    A.Transpose(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, p=0.3),\n",
    "    A.OneOf([\n",
    "            A.MotionBlur(blur_limit=5, p=0.5),\n",
    "            A.MedianBlur(blur_limit=5, p=0.5),\n",
    "            A.GaussianBlur(blur_limit=5, p=0.5),\n",
    "        ], p=0.2),\n",
    "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.1),\n",
    "    # A.OpticalDistortion(distort_limit=0.5, p=0.3),\n",
    "    # A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.3),\n",
    "    # A.ElasticTransform(alpha=1, p=0.3),\n",
    "    # A.CLAHE(clip_limit=2.0, p=0.3),\n",
    "    # A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=5, p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.3),\n",
    "    A.CoarseDropout(max_holes=20, min_holes=10, p=0.3),\n",
    "    A.Resize(CFG.img_size, CFG.img_size),\n",
    "    # A.Normalize(\n",
    "    #                 mean=[0.485, 0.456, 0.406], \n",
    "    #                 std=[0.229, 0.224, 0.225], \n",
    "    #                 max_pixel_value=255.0, \n",
    "    #                 p=1.0\n",
    "    #             ),\n",
    "    ToTensorV2(p=1)\n",
    "    ])\n",
    "    augmentations_train_light = A.Compose([\n",
    "        A.Transpose(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, p=0.1),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(blur_limit=5, p=0.5),\n",
    "            A.MedianBlur(blur_limit=5, p=0.5),\n",
    "            A.GaussianBlur(blur_limit=5, p=0.5),\n",
    "        ], p=0.1),\n",
    "        # A.GaussNoise(var_limit=(5.0, 30.0), p=0.5),\n",
    "        # A.OpticalDistortion(distort_limit=0.5, p=0.5),\n",
    "        # A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
    "        # A.ElasticTransform(alpha=1, p=0.5),\n",
    "        # A.CLAHE(clip_limit=2.0, p=0.5),\n",
    "        # A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=5, p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.2),\n",
    "        A.CoarseDropout(max_holes=30, min_holes=20, p=0.2),\n",
    "        A.Resize(CFG.img_size, CFG.img_size),\n",
    "        # A.Normalize(\n",
    "        #                 mean=[0.485, 0.456, 0.406], \n",
    "        #                 std=[0.229, 0.224, 0.225], \n",
    "        #                 max_pixel_value=255.0, \n",
    "        #                 p=1.0\n",
    "        #             ),\n",
    "        ToTensorV2(p=1)\n",
    "    ])\n",
    "    \n",
    "    augmentations_test = A.Compose([\n",
    "        A.Resize(CFG.img_size, CFG.img_size),\n",
    "        # A.Normalize(\n",
    "        #                 mean=[0.485, 0.456, 0.406], \n",
    "        #                 std=[0.229, 0.224, 0.225], \n",
    "        #                 max_pixel_value=255.0, \n",
    "        #                 p=1.0\n",
    "        #             ),\n",
    "        ToTensorV2(p=1)\n",
    "    ])\n",
    "    if include_light:\n",
    "        return augmentations_train, augmentations_test, augmentations_train_light\n",
    "    return augmentations_train, augmentations_test\n",
    "\n",
    "# def get_transforms():\n",
    "#     data_transforms = {\n",
    "#         \"train\": A.Compose([\n",
    "#             A.Resize(CFG.img_size, CFG.img_size),\n",
    "#             A.RandomRotate90(p=0.5),\n",
    "#             A.Flip(p=0.5),\n",
    "#             A.Downscale(p=0.25),\n",
    "#             A.ShiftScaleRotate(shift_limit=0.1, \n",
    "#                             scale_limit=0.15, \n",
    "#                             rotate_limit=60, \n",
    "#                             p=0.5),\n",
    "#             A.HueSaturationValue(\n",
    "#                     hue_shift_limit=0.2, \n",
    "#                     sat_shift_limit=0.2, \n",
    "#                     val_shift_limit=0.2, \n",
    "#                     p=0.5\n",
    "#                 ),\n",
    "#             A.RandomBrightnessContrast(\n",
    "#                     brightness_limit=(-0.1,0.1), \n",
    "#                     contrast_limit=(-0.1, 0.1), \n",
    "#                     p=0.5\n",
    "#                 ),\n",
    "#             A.Normalize(\n",
    "#                     mean=[0.485, 0.456, 0.406], \n",
    "#                     std=[0.229, 0.224, 0.225], \n",
    "#                     max_pixel_value=255.0, \n",
    "#                     p=1.0\n",
    "#                 ),\n",
    "#             ToTensorV2()], p=1.),\n",
    "        \n",
    "#         \"valid\": A.Compose([\n",
    "#             A.Resize(CFG.img_size, CFG.img_size),\n",
    "#             A.Normalize(\n",
    "#                     mean=[0.485, 0.456, 0.406], \n",
    "#                     std=[0.229, 0.224, 0.225], \n",
    "#                     max_pixel_value=255.0, \n",
    "#                     p=1.0\n",
    "#                 ),\n",
    "#             ToTensorV2()], p=1.)\n",
    "#     }\n",
    "#     return data_transforms[\"train\"], data_transforms[\"valid\"]\n",
    "\n",
    "# def get_transforms():\n",
    "#     train_transforms = A.Compose([\n",
    "#         A.Transpose(p=0.5),\n",
    "#         A.VerticalFlip(p=0.5),\n",
    "#         A.HorizontalFlip(p=0.5),\n",
    "#         A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.75),\n",
    "#         A.OneOf([\n",
    "#             A.MotionBlur(blur_limit=5),\n",
    "#             A.MedianBlur(blur_limit=5),\n",
    "#             A.GaussianBlur(blur_limit=5),\n",
    "#             A.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "#         ], p=0.7),\n",
    "\n",
    "#         A.OneOf([\n",
    "#             A.OpticalDistortion(distort_limit=1.0),\n",
    "#             A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "#             A.ElasticTransform(alpha=3),\n",
    "#         ], p=0.7),\n",
    "\n",
    "#         A.CLAHE(clip_limit=4.0, p=0.7),\n",
    "#         A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
    "#         A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
    "#         A.Resize(CFG.img_size, CFG.img_size),\n",
    "#         A.CoarseDropout(max_height=int(CFG.img_size * 0.375), max_width=int(CFG.img_size * 0.375), max_holes=1, min_holes=1, p=0.7),    \n",
    "#         A.Normalize()\n",
    "#     ])\n",
    "\n",
    "#     val_transforms = A.Compose([\n",
    "#         A.Resize(CFG.img_size, CFG.img_size),\n",
    "#         A.Normalize()\n",
    "#     ])\n",
    "\n",
    "#     return train_transforms, val_transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                df: pd.DataFrame,\n",
    "                fp_hdf: str|Path,\n",
    "                transform: A.Compose=None,\n",
    "                ):\n",
    "        self.df = df\n",
    "        if 'target' in self.df.columns:\n",
    "            self.is_training = True\n",
    "            self.targets = df['target'].values\n",
    "        else:\n",
    "            self.is_training = False\n",
    "        self.fp_hdf = h5py.File(fp_hdf, mode=\"r\")\n",
    "        self.isic_ids = df['isic_id'].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        isic_id = self.isic_ids[index]\n",
    "        image = np.array(Image.open(BytesIO(self.fp_hdf[isic_id][()])))\n",
    "        if self.is_training:\n",
    "            target = self.targets[index]\n",
    "        else:\n",
    "            target = []\n",
    "        \n",
    "        if self.transform:\n",
    "            return (self._apply_transform(image), target)\n",
    "        else:\n",
    "            return (image, target)\n",
    "    \n",
    "    def _apply_transform(self, img:np.ndarray):\n",
    "        \"\"\"apply transform to image\"\"\"\n",
    "        transformed = self.transform(image=img)\n",
    "        img = transformed[\"image\"]# .float()# .half()\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def F_rgb2hsv(rgb: torch.Tensor) -> torch.Tensor:\n",
    "    cmax, cmax_idx = torch.max(rgb, dim=1, keepdim=True)\n",
    "    cmin = torch.min(rgb, dim=1, keepdim=True)[0]\n",
    "    delta = cmax - cmin\n",
    "    hsv_h = torch.empty_like(rgb[:, 0:1, :, :])\n",
    "    cmax_idx[delta == 0] = 3\n",
    "    hsv_h[cmax_idx == 0] = (((rgb[:, 1:2] - rgb[:, 2:3]) / delta) % 6)[cmax_idx == 0]\n",
    "    hsv_h[cmax_idx == 1] = (((rgb[:, 2:3] - rgb[:, 0:1]) / delta) + 2)[cmax_idx == 1]\n",
    "    hsv_h[cmax_idx == 2] = (((rgb[:, 0:1] - rgb[:, 1:2]) / delta) + 4)[cmax_idx == 2]\n",
    "    hsv_h[cmax_idx == 3] = 0.\n",
    "    hsv_h /= 6.\n",
    "    hsv_s = torch.where(cmax == 0, torch.tensor(0.).type_as(rgb), delta / cmax)\n",
    "    hsv_v = cmax\n",
    "    return torch.cat([hsv_h, hsv_s, hsv_v], dim=1)\n",
    "\n",
    "\n",
    "class timmModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name: str,\n",
    "            pretrained: bool,\n",
    "            in_channels: int,\n",
    "            num_classes: int,\n",
    "            is_training: bool=False\n",
    "        ):\n",
    "        super().__init__()\n",
    "        if 'eva' in CFG.model_name:\n",
    "            self.model = timm.create_model(\n",
    "                model_name=model_name, \n",
    "                pretrained=pretrained, \n",
    "                in_chans=in_channels,\n",
    "                num_classes=num_classes,\n",
    "                # global_pool=''\n",
    "            )\n",
    "        else:\n",
    "            self.model = timm.create_model(\n",
    "                model_name=model_name, \n",
    "                pretrained=pretrained, \n",
    "                in_chans=in_channels,\n",
    "                num_classes=num_classes,\n",
    "                global_pool=''\n",
    "            )\n",
    "        \n",
    "        self.output_type = ['infer', 'loss']\n",
    "        self.is_training = is_training\n",
    "\n",
    "        # model output dim\n",
    "        dim = CFG.output_dim_models[CFG.model_name]\n",
    "        \n",
    "        self.dropout = nn.ModuleList([\n",
    "            nn.Dropout(0.5) for i in range(5)\n",
    "        ])\n",
    "        self.target=nn.Linear(dim, 1)\n",
    "        # self.target_aux=nn.Linear(dim, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        batch_size = len(x)\n",
    "        \n",
    "        x = torch.cat([x, F_rgb2hsv(x)],1) # (bs, dim, h, w)\n",
    "        x = self.model(x)    \n",
    "        # print('model output: ', x.shape)\n",
    "        \n",
    "        if not 'eva' in CFG.model_name:\n",
    "            pool = F.adaptive_avg_pool2d(x, 1)\n",
    "            # print('after pooling: ', pool.shape)\n",
    "            reshaped = pool.reshape(batch_size, -1)  \n",
    "            # print('after reshape: ', reshaped.shape)\n",
    "        \n",
    "        else:\n",
    "            reshaped = x\n",
    "        \n",
    "        if self.is_training:\n",
    "            logit = 0\n",
    "            # print(len(self.dropout))\n",
    "            for i in range(len(self.dropout)):\n",
    "                dropped = self.dropout[i](reshaped)\n",
    "                # print(dropped.shape)\n",
    "                logit += self.target(dropped)\n",
    "            logit = logit / len(self.dropout)\n",
    "        else:\n",
    "            logit = self.target(reshaped)\n",
    "            \n",
    "        output = {}\n",
    "        if 'loss' in self.output_type:\n",
    "            if target.dim() == 1:\n",
    "                target = target.view(-1, 1)\n",
    "            output['bce_loss'] = F.binary_cross_entropy_with_logits(logit.float(), target.float())\n",
    "\n",
    "        if 'infer' in self.output_type:\n",
    "            output['target'] = torch.sigmoid(logit.float())\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "\n",
    "    if CFG.view:\n",
    "        def show_batch(ds, row=3, col=3, color='rgb'):\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            img_index = np.random.randint(0, len(ds)-1, row*col)\n",
    "            \n",
    "            for i in range(len(img_index)):\n",
    "                img, label = ds[img_index[i]]\n",
    "                img_rgb = img[:3, :, :]\n",
    "                # img_hsv = img[3:6, :, :]\n",
    "                \n",
    "                if color=='rgb':\n",
    "                    img = img_rgb\n",
    "                # elif color=='hsv':\n",
    "                #     img = img_hsv\n",
    "                \n",
    "                if isinstance(img, torch.Tensor):\n",
    "                    img = img.detach().numpy()\n",
    "                    # Check if the image is in (C, H, W) and transpose it to (H, W, C)\n",
    "                    if img.shape[0] == 3:  # Assuming the image is (C, H, W)\n",
    "                        img = np.transpose(img, (1, 2, 0))\n",
    "                \n",
    "                ax = fig.add_subplot(row, col, i + 1, xticks=[], yticks=[])\n",
    "                ax.imshow(img)  # Remove cmap parameter for RGB images\n",
    "                ax.set_title(f'ID: {img_index[i]}; Target: {label}')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        _train_transform, _ = get_transforms()\n",
    "        _dataset = ISICDataset(df=train_meta, fp_hdf=CFG.TRAIN_HDF5, transform=_train_transform)\n",
    "        show_batch(_dataset)\n",
    "        # show_batch(_dataset, color='hsv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "\n",
    "    # reference\n",
    "    def train_one_fold(val_fold: int, \n",
    "                    train: pd.DataFrame,\n",
    "                    output_path: str|Path\n",
    "                    ):\n",
    "        \"\"\"Main\"\"\"\n",
    "        # If True, forces cuDNN to benchmark multiple convolution algorithms and choose the fastest one\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        set_random_seed(CFG.random_seed, deterministic=CFG.deterministic)\n",
    "        # set device with pytorch env\n",
    "        device = torch.device(CFG.device)\n",
    "        # print(device)\n",
    "        \n",
    "        train_transform, val_transform = get_transforms()\n",
    "        \n",
    "    #     train_dataset = Bird2024Dataset(**train_path_label, transform=train_transform)\n",
    "        train_dataset = ISICDataset(train[train['fold']!=val_fold], CFG.TRAIN_HDF5, train_transform)\n",
    "        train_dataset_noaugment = ISICDataset(train[train['fold']!=val_fold], CFG.TRAIN_HDF5, val_transform)\n",
    "        val_dataset = ISICDataset(train[train['fold']==val_fold], CFG.TRAIN_HDF5, val_transform)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=True, drop_last=True)\n",
    "        train_loader_noaugment = torch.utils.data.DataLoader(\n",
    "            train_dataset_noaugment, batch_size=CFG.batch_size, num_workers=4, shuffle=True, drop_last=True)\n",
    "        \n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "        \n",
    "        model = timmModel(\n",
    "            model_name=CFG.model_name, \n",
    "            pretrained=CFG.pretrained, \n",
    "            num_classes=0, # no classification head\n",
    "            in_channels=6, # RBG+HSV\n",
    "            is_training=True\n",
    "        )\n",
    "        # transfer learning\n",
    "        if CFG.PRETRAINED_MODEL:\n",
    "            model.load_state_dict(torch.load(CFG.PRETRAINED_MODEL, map_location=device))\n",
    "            \n",
    "        model = model.to(device)\n",
    "\n",
    "        \n",
    "        optimizer = optim.AdamW(params=model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "        scheduler = lr_scheduler.OneCycleLR(\n",
    "            optimizer=optimizer, epochs=CFG.max_epoch,\n",
    "            pct_start=0.0, steps_per_epoch=len(train_loader),\n",
    "            max_lr=CFG.lr, div_factor=25, final_div_factor=1e4\n",
    "        )\n",
    "        \n",
    "    #     loss_func = KLDivLossWithLogits()\n",
    "        # loss_func = nn.CrossEntropyLoss()\n",
    "        # loss_func = nn.BCEWithLogitsLoss()\n",
    "    #     loss_func = FocalLossBCE()\n",
    "        # loss_func.to(device)\n",
    "    #     loss_func_val = KLDivLossWithLogitsForVal()\n",
    "    #     loss_func_val = nn.CrossEntropyLoss()\n",
    "        # loss_func_val = nn.BCEWithLogitsLoss()\n",
    "    #     loss_func_val = FocalLossBCE()\n",
    "        \n",
    "        use_amp = CFG.enable_amp\n",
    "        scaler = amp.GradScaler(enabled=use_amp)\n",
    "        \n",
    "        best_val_loss = 1.0e+09\n",
    "        best_epoch = 0\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        for epoch in range(1, CFG.max_epoch + 1):\n",
    "            if CFG.change_dataset & epoch >= ((CFG.max_epoch+1) * 0.6):\n",
    "                train_loader = train_loader_noaugment\n",
    "            epoch_start = time()\n",
    "            model.train()\n",
    "            for batch in tqdm(train_loader):\n",
    "                \n",
    "                x, t = batch\n",
    "                if CFG.standardization:\n",
    "                    x = (x - x.min()) / (x.max() - x.min() +1e-6) * 255\n",
    "                else:\n",
    "                    x = x.float()/255\n",
    "                # t = t.float()\n",
    "    #             print(x)\n",
    "    #             print(t)\n",
    "                x = to_device(x, device)\n",
    "                t = to_device(t, device)\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "                with amp.autocast(use_amp):\n",
    "                    output = model(x, t)\n",
    "                    loss = output['bce_loss']\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                train_loss += loss.item()\n",
    "                scheduler.step()\n",
    "                \n",
    "            train_loss /= len(train_loader)\n",
    "                \n",
    "            model.eval()\n",
    "            for batch in tqdm(val_loader):\n",
    "                x, t = batch\n",
    "                if CFG.standardization:\n",
    "                    x = (x - x.min()) / (x.max() - x.min() +1e-6) * 255\n",
    "                else:\n",
    "                    x = x.float()/255\n",
    "                x = to_device(x, device)\n",
    "                t = to_device(t, device)\n",
    "                with torch.no_grad(), amp.autocast(use_amp):\n",
    "                    output = model(x, t)\n",
    "                loss = output['bce_loss']\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_epoch = epoch\n",
    "                best_val_loss = val_loss\n",
    "                # print(\"save model\")\n",
    "                torch.save(model.state_dict(), str(output_path / f'snapshot_epoch_{epoch}.pth'))\n",
    "            \n",
    "            elapsed_time = time() - epoch_start\n",
    "            print(\n",
    "                f\"[epoch {epoch}] train loss: {train_loss: .6f}, val loss: {val_loss: .6f}, elapsed_time: {elapsed_time: .3f}\")\n",
    "            \n",
    "            if epoch - best_epoch > CFG.es_patience:\n",
    "                print(\"Early Stopping!\")\n",
    "                break\n",
    "                \n",
    "            train_loss = 0\n",
    "            val_loss = 0\n",
    "                \n",
    "        return val_fold, best_epoch, best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    score_list = []\n",
    "    print('='*20)\n",
    "    print('experiment: ', CFG.exp)\n",
    "    print('='*20)\n",
    "    for fold_id in range(CFG.n_folds):\n",
    "        output_path = CFG.OUTPUT_DIR / f\"fold{fold_id}\"\n",
    "        output_path.mkdir(exist_ok=True)\n",
    "        print(f\"[fold{fold_id}]\")\n",
    "        score_list.append(train_one_fold(fold_id, train_meta, output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    print(score_list)\n",
    "    score_list_log = score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "\n",
    "    # select the best model and delete others\n",
    "    best_log_list = []\n",
    "    for (fold_id, best_epoch, _) in score_list:\n",
    "        \n",
    "        # select the best model\n",
    "        exp_dir_path = CFG.OUTPUT_DIR / f\"fold{fold_id}\"\n",
    "        best_model_path = exp_dir_path / f\"snapshot_epoch_{best_epoch}.pth\"\n",
    "        # copy to new place\n",
    "        copy_to = CFG.OUTPUT_DIR / f\"./best_model_fold{fold_id}.pth\"\n",
    "        shutil.copy(best_model_path, copy_to)\n",
    "        \n",
    "        for p in exp_dir_path.glob(\"*.pth\"):\n",
    "            # delete\n",
    "            p.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for inference\n",
    "def run_inference_loop(model, loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    model.output_type = ['infer']\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            x = to_device(batch[0], device)\n",
    "            if CFG.standardization:\n",
    "                x = (x - x.min()) / (x.max() - x.min() +1e-6) * 255\n",
    "            else:\n",
    "                x = x.float()/255\n",
    "            output = model(x)\n",
    "            y = output['target']\n",
    "            pred_list.append(y.detach().cpu().numpy())\n",
    "    \n",
    "    # concatenate to vertical (to df like from long scroll like)\n",
    "    pred_arr = np.concatenate(pred_list)\n",
    "    del pred_list\n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "\n",
    "    # predict for train data with metrix(CV. not test data)\n",
    "\n",
    "\n",
    "    # duplicate check\n",
    "    column_to_check = 'isic_id'\n",
    "    # Drop duplicate rows based on the specified column\n",
    "    train_meta = train_meta.drop_duplicates(subset=[column_to_check], keep='first').reset_index()\n",
    "\n",
    "    # label_arr = train[CLASSES].values\n",
    "    oof_pred_arr = np.zeros((len(train_meta), CFG.n_classes-1))\n",
    "    score_list = []\n",
    "\n",
    "    for fold_id in range(CFG.n_folds):\n",
    "        print(f\"\\n[fold {fold_id}]\")\n",
    "        device = torch.device(CFG.device)\n",
    "\n",
    "        # get_dataloader\n",
    "        _, val_transform = get_transforms()\n",
    "        val_dataset = ISICDataset(df=train_meta[train_meta[\"fold\"] == fold_id], fp_hdf=CFG.TRAIN_HDF5, transform=val_transform)\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "\n",
    "        # # get model\n",
    "        model_path = CFG.OUTPUT_DIR / f\"best_model_fold{fold_id}.pth\"\n",
    "        model = timmModel(\n",
    "            model_name=CFG.model_name, \n",
    "            pretrained=False, \n",
    "            in_channels=6,\n",
    "            num_classes=0,\n",
    "            is_training=False\n",
    "        )\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "        # # inference\n",
    "        val_pred = run_inference_loop(model, val_loader, device)\n",
    "        val_idx = train_meta[train_meta[\"fold\"] == fold_id].index.values\n",
    "        oof_pred_arr[val_idx] = val_pred\n",
    "\n",
    "        del val_idx\n",
    "        del model, val_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80):\n",
    "        v_gt = abs(np.asarray(solution.values)-1)\n",
    "        v_pred = np.array([1.0 - x for x in submission.values])\n",
    "        max_fpr = abs(1-min_tpr)\n",
    "        partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "        # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "        # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "        partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "        return partial_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    # make true array\n",
    "    label_arr = train_meta['target']\n",
    "    # one-hot\n",
    "    # ture_arr = np.zeros((label_arr.size, CFG.n_classes))\n",
    "    # ture_arr[np.arange(label_arr.size), label_arr] = 1\n",
    "    ture_arr = pd.DataFrame(label_arr)\n",
    "\n",
    "    # oof\n",
    "    oof = pd.DataFrame(oof_pred_arr)\n",
    "\n",
    "    micro_roc_auc_ovr = comp_score(\n",
    "        ture_arr,\n",
    "        oof,\n",
    "        \"\"\n",
    "    )\n",
    "\n",
    "    print(f\"CV: Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    with open(CFG.OUTPUT_LOG, 'a') as f:\n",
    "        f.write('\\n')\n",
    "        f.write(f'exp: {CFG.exp}')\n",
    "        f.write('\\n')\n",
    "        f.write(str(score_list_log))\n",
    "        f.write('\\n')\n",
    "        f.write(f\"CV: Micro-averaged One-vs-Rest ROC AUC score: {micro_roc_auc_ovr:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.is_infer:\n",
    "\n",
    "    display(oof.head())\n",
    "    display(ture_arr.head())\n",
    "    display(oof.tail())\n",
    "    display(ture_arr.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for test data with metrix\n",
    "if CFG.is_kaggle & CFG.is_infer:\n",
    "\n",
    "    pred_arr = []\n",
    "\n",
    "    for fold_id in range(CFG.n_folds):\n",
    "        print(f\"\\n[fold {fold_id}]\")\n",
    "        device = torch.device(CFG.device)\n",
    "\n",
    "        # get_dataloader\n",
    "        _, val_transform = get_transforms()\n",
    "        val_dataset = ISICDataset(df=test_meta, fp_hdf=CFG.TEST_HDF5, transform=val_transform)\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=CFG.batch_size, num_workers=2, shuffle=False, drop_last=False)\n",
    "\n",
    "        # get model\n",
    "        model_path = CFG.OUTPUT_DIR / f\"best_model_fold{fold_id}.pth\"\n",
    "        model = timmModel(\n",
    "            model_name=CFG.model_name, \n",
    "            pretrained=False, \n",
    "            in_channels=6,\n",
    "            num_classes=0,\n",
    "            is_training=False\n",
    "        )\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "        # # inference\n",
    "        val_pred = run_inference_loop(model, val_loader, device)\n",
    "        pred_arr.append(val_pred)\n",
    "\n",
    "        del model, val_loader, val_pred\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    # averaging\n",
    "    print(len(pred_arr))\n",
    "    if len(pred_arr) >= 2:    \n",
    "        pred_arr = np.mean(pred_arr, axis=0)\n",
    "    print(pred_arr.shape)\n",
    "\n",
    "    pred_df = pd.DataFrame(pred_arr)\n",
    "    display(pred_df)\n",
    "\n",
    "    # submission\n",
    "    df_sub = pd.read_csv(CFG.SAMPLE_SUB)\n",
    "    df_sub[\"target\"] = pred_df\n",
    "    display(df_sub.head())\n",
    "    df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
